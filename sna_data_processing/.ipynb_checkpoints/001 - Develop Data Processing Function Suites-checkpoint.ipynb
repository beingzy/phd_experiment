{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.4f'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%precision 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ROOT_DIR = os.getcwd()\n",
    "_DATA_DIR = os.path.join(_ROOT_DIR, 'data')\n",
    "_OUTPUT_DIR = os.path.join(_ROOT_DIR, 'output')\n",
    "\n",
    "_GPLUS_PATH = os.path.join(_DATA_DIR, 'gplus')\n",
    "_FB_PATH = os.path.join(_DATA_DIR, 'facebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\A605739\\\\Dropbox\\\\phd\\\\phd_experiment\\\\sna_data_processing\\\\output'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A package of SNAP social network data is consisted of a several sets of data files, each of which reprsents a circle:\n",
    "* circles\n",
    "* edges\n",
    "* egofeat\n",
    "* feat\n",
    "* featnames\n",
    "* followers (only for Google+)\n",
    "\n",
    "The objective of the output is to consolidate the information scattered across different files into a single data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total of circles in GPlus: 132\n",
      "the total of circles in Facebook: 10\n"
     ]
    }
   ],
   "source": [
    "gp_file_group_ids = pd.Series(os.listdir(_GPLUS_PATH)).apply(lambda x: x.split('.')[0]).unique().tolist()\n",
    "print( \"the total of circles in GPlus: {}\".format(len(gp_file_group_ids)) )\n",
    "\n",
    "fb_file_group_ids = pd.Series(os.listdir(_FB_PATH)).apply(lambda x: x.split('.')[0]).unique().tolist()\n",
    "print( \"the total of circles in Facebook: {}\".format(len(fb_file_group_ids)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of feature of 0 file group: 224\n",
      "The number of feature of 107 file group: 576\n",
      "The number of feature of 1684 file group: 319\n",
      "The number of feature of 1912 file group: 480\n",
      "The number of feature of 3437 file group: 262\n",
      "The number of feature of 348 file group: 161\n",
      "The number of feature of 3980 file group: 42\n",
      "The number of feature of 414 file group: 105\n",
      "The number of feature of 686 file group: 63\n",
      "The number of feature of 698 file group: 48\n"
     ]
    }
   ],
   "source": [
    "for ii, file_group in enumerate(fb_file_group_ids):\n",
    "    # display the number features in *.feat\n",
    "    file_path = os.path.join(_FB_PATH, file_group+'.featnames')\n",
    "    table = pd.read_csv(file_path, header=None)\n",
    "    print(\"The number of feature of {} file group: {}\".format(file_group, table.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_group = fb_file_group_ids[0]\n",
    "\n",
    "feat_fpath = os.path.join(_FB_PATH, file_group+'.feat')\n",
    "featnames_fpath = os.path.join(_FB_PATH, file_group+'.featnames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   215  216  217  218  \\\n",
       "0    1    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    2    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    3    0    0    0    0    0    0    0    1    0 ...     0    0    0    1   \n",
       "3    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    5    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   219  220  221  222  223  224  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 225 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get featnames\n",
    "feat_df = pd.read_csv(feat_fpath, header=None, sep=\" \")\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featnames_df_proc(file_path):\n",
    "    \"\"\" process .featnames file to clean the data and keep\n",
    "        the processed data in dataframe(index, feat_name, value)\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    items = []\n",
    "    with open(file_path, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.replace(\"anonymized feature\", \"\").strip()\n",
    "            comps = re.split(\" \", line)\n",
    "            idx, featname, val = comps[0], comps[1], comps[2]\n",
    "            idx = int(idx)\n",
    "            featname = featname[:-1].replace(\";\", \"_\")\n",
    "            val = int(val.split(\" \")[-1])\n",
    "            item = {'index': idx, 'feat_name': featname, 'value': val}\n",
    "            items.append(item)\n",
    "        \n",
    "    featname_df = pd.DataFrame(items)\n",
    "    return featname_df\n",
    "\n",
    "def feat_list_proc(file_path, featname_df, prefix=\"\"):\n",
    "    \"\"\" convert dummy variable form dataframe \n",
    "        into list of user's profile, stored as dictionary of featname:value\n",
    "        \n",
    "        Arguments:\n",
    "        ==========\n",
    "        * file_path: <string>\n",
    "        * featname_df: <pandas.DataFrame>\n",
    "        * prefix: <string>\n",
    "    \"\"\"\n",
    "    \n",
    "    def pair_key_value(x):\n",
    "        \"\"\"create key:value pair string\"\"\"\n",
    "        x = [str(ii) for ii in x]\n",
    "        return \":\".join(x)\n",
    "\n",
    "    featname_columns = ['feat_name', 'value']\n",
    "\n",
    "    users = []\n",
    "    with open(feat_fpath, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            comps = line.split(' ')\n",
    "            uid, feat_codes = comps[0], comps[1:]\n",
    "        \n",
    "            nzero_idx = [ii for ii, val in enumerate(feat_codes) if val != '0']\n",
    "            kv_pairs = featname_df.loc[nzero_idx, featname_columns].apply(pair_key_value, axis=1).tolist()\n",
    "            profile = {kv.split(\":\")[0]:kv.split(\":\")[1] for kv in kv_pairs}\n",
    "            \n",
    "            if prefix != \"\": \n",
    "                uid = prefix + '_' + uid\n",
    "   \n",
    "            profile['uid'] = uid\n",
    "            users.append(profile)\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- total of users: 4,167 ---\n",
      "--- time cost: 5.42s ---\n"
     ]
    }
   ],
   "source": [
    "# create a single table to keep profiles of all users appearing in\n",
    "# the network \n",
    "start_at = time.time()\n",
    "\n",
    "users = []\n",
    "for file_group in fb_file_group_ids:\n",
    "    feat_fpath = os.path.join(_FB_PATH, file_group+'.feat')\n",
    "    featnames_fpath = os.path.join(_FB_PATH, file_group+'.featnames')\n",
    "    \n",
    "    featname_df = featnames_df_proc(featnames_fpath)\n",
    "    user_profile_list = feat_list_proc(feat_fpath, featname_df)\n",
    "    users.extend(user_profile_list)\n",
    "\n",
    "end_at = time.time()\n",
    "print(\"--- total of users: {:,} ---\".format(len(users)))\n",
    "print(\"--- time cost: {:.2f}s ---\".format(end_at - start_at))\n",
    "\n",
    "users_df = pd.DataFrame(users)\n",
    "col_names = users_df.columns.tolist()\n",
    "col_names = ['uid'] + [colname for colname in col_names if col_names != 'uid']\n",
    "users_df = users_df[col_names]\n",
    "users_df.to_csv(os.path.join(_OUTPUT_DIR, 'facebook_users.csv'), sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- total of edges: 170,174 ---\n",
      "--- time cost: 0.21s ---\n"
     ]
    }
   ],
   "source": [
    "# compile all edge files together and output a single consolidated\n",
    "# .csv file\n",
    "start_at = time.time()\n",
    "\n",
    "edge_pairs = []\n",
    "for file_group in fb_file_group_ids:\n",
    "    edge_fpath = os.path.join(_FB_PATH, file_group+'.edges')\n",
    "    with open(edge_fpath, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            pair = line.strip().split(\" \")\n",
    "            pair_dict = {\"user_a\":pair[0], \"user_b\":pair[1]}\n",
    "            edge_pairs.append(pair_dict)\n",
    "\n",
    "end_at = time.time()\n",
    "print(\"--- total of edges: {:,} ---\".format(len(edge_pairs)))\n",
    "print(\"--- time cost: {:.2f}s ---\".format(end_at - start_at))\n",
    "\n",
    "edges_df = pd.DataFrame(edge_pairs)\n",
    "edges_df.to_csv(os.path.join(_OUTPUT_DIR, 'facebook_edges.csv'), sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>birthday</th>\n",
       "      <th>education_classes_id</th>\n",
       "      <th>education_concentration_id</th>\n",
       "      <th>education_degree_id</th>\n",
       "      <th>education_school_id</th>\n",
       "      <th>education_type</th>\n",
       "      <th>education_with_id</th>\n",
       "      <th>education_year_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>...</th>\n",
       "      <th>religion</th>\n",
       "      <th>uid</th>\n",
       "      <th>work_employer_id</th>\n",
       "      <th>work_end_date</th>\n",
       "      <th>work_from_id</th>\n",
       "      <th>work_location_id</th>\n",
       "      <th>work_position_id</th>\n",
       "      <th>work_projects_id</th>\n",
       "      <th>work_start_date</th>\n",
       "      <th>work_with_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4167</td>\n",
       "      <td>1597</td>\n",
       "      <td>65</td>\n",
       "      <td>1220</td>\n",
       "      <td>483</td>\n",
       "      <td>2781</td>\n",
       "      <td>3103</td>\n",
       "      <td>33</td>\n",
       "      <td>2471</td>\n",
       "      <td>334</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4167</td>\n",
       "      <td>646</td>\n",
       "      <td>929</td>\n",
       "      <td>4</td>\n",
       "      <td>617</td>\n",
       "      <td>390</td>\n",
       "      <td>20</td>\n",
       "      <td>1091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4035</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>97</td>\n",
       "      <td>24</td>\n",
       "      <td>249</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4035</td>\n",
       "      <td>139</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>428</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>538</td>\n",
       "      <td>55</td>\n",
       "      <td>350</td>\n",
       "      <td>66</td>\n",
       "      <td>1065</td>\n",
       "      <td>...</td>\n",
       "      <td>1154</td>\n",
       "      <td>428</td>\n",
       "      <td>140</td>\n",
       "      <td>157</td>\n",
       "      <td>683</td>\n",
       "      <td>84</td>\n",
       "      <td>193</td>\n",
       "      <td>712</td>\n",
       "      <td>157</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>376</td>\n",
       "      <td>9</td>\n",
       "      <td>313</td>\n",
       "      <td>211</td>\n",
       "      <td>640</td>\n",
       "      <td>2620</td>\n",
       "      <td>10</td>\n",
       "      <td>358</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>373</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>314</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid birthday education_classes_id education_concentration_id  \\\n",
       "count   4167     1597                   65                       1220   \n",
       "unique  4035       40                   23                         97   \n",
       "top      428        5                  336                         14   \n",
       "freq       4      376                    9                        313   \n",
       "\n",
       "       education_degree_id education_school_id education_type  \\\n",
       "count                  483                2781           3103   \n",
       "unique                  24                 249              3   \n",
       "top                     22                 538             55   \n",
       "freq                   211                 640           2620   \n",
       "\n",
       "       education_with_id education_year_id first_name     ...      religion  \\\n",
       "count                 33              2471        334     ...             2   \n",
       "unique                12                34         71     ...             1   \n",
       "top                  350                66       1065     ...          1154   \n",
       "freq                  10               358         18     ...             2   \n",
       "\n",
       "         uid work_employer_id work_end_date work_from_id work_location_id  \\\n",
       "count   4167              646           929            4              617   \n",
       "unique  4035              139            40            2               48   \n",
       "top      428              140           157          683               84   \n",
       "freq       4               49           373            2               89   \n",
       "\n",
       "       work_position_id work_projects_id work_start_date work_with_id  \n",
       "count               390               20            1091            8  \n",
       "unique               60               10              61            4  \n",
       "top                 193              712             157          728  \n",
       "freq                 82                3             314            2  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"253 job_title:economics,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\A605739\\\\Dropbox\\\\phd\\\\phd_experiment\\\\sna_data_processing\\\\data\\\\gplus\\\\100129275726588145876.featnames'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gplus_featnames_df_proc(file_path):\n",
    "    \"\"\" process .featnames file to clean the data and keep\n",
    "        the processed data in dataframe(index, feat_name, value)\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    items = []\n",
    "    with open(file_path, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.replace(\":\", ' ').replace(\",\", \"\")\n",
    "            comps = line.split(\" \")\n",
    "            idx, featname, val = comps[0], comps[1], comps[2]\n",
    "            idx = int(idx)\n",
    "            featname = featname[:-1].replace(\";\", \"_\")\n",
    "            val = int(val.split(\" \")[-1])\n",
    "            item = {'index': idx, 'feat_name': featname, 'value': val}\n",
    "            items.append(item)\n",
    "        \n",
    "    featname_df = pd.DataFrame(items)\n",
    "    return featname_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-b8b067bd321d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfeatnames_fpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GPLUS_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_group\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.featnames'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfeatname_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatnames_df_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatnames_fpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0muser_profile_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat_list_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_fpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatname_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0musers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_profile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-182-aea443e23d0d>\u001b[0m in \u001b[0;36mfeatnames_df_proc\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"anonymized feature\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcomps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mfeatname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "##\n",
    "## process gplus data\n",
    "##\n",
    "start_at = time.time()\n",
    "\n",
    "users = []\n",
    "for file_group in gp_file_group_ids:\n",
    "    feat_fpath = os.path.join(_GPLUS_PATH, file_group+'.feat')\n",
    "    featnames_fpath = os.path.join(_GPLUS_PATH, file_group+'.featnames')\n",
    "    \n",
    "    featname_df = featnames_df_proc(featnames_fpath)\n",
    "    user_profile_list = feat_list_proc(feat_fpath, featname_df)\n",
    "    users.extend(user_profile_list)\n",
    "\n",
    "end_at = time.time()\n",
    "print(\"--- total of users: {:,} ---\".format(len(users)))\n",
    "print(\"--- time cost: {:.2f}s ---\".format(end_at - start_at))\n",
    "\n",
    "users_df = pd.DataFrame(users)\n",
    "col_names = users_df.columns.tolist()\n",
    "col_names = ['uid'] + [colname for colname in col_names if col_names != 'uid']\n",
    "users_df = users_df[col_names]\n",
    "users_df.to_csv(os.path.join(_OUTPUT_DIR, 'gplus_users.csv'), sep=',', header=True, index=False)\n",
    "\n",
    "\n",
    "# compile all edge files together and output a single consolidated\n",
    "# .csv file\n",
    "start_at = time.time()\n",
    "\n",
    "edge_pairs = []\n",
    "for file_group in gp_file_group_ids:\n",
    "    edge_fpath = os.path.join(_GPLUS_PATH, file_group+'.edges')\n",
    "    with open(edge_fpath, mode='r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            pair = line.strip().split(\" \")\n",
    "            pair_dict = {\"user_a\":pair[0], \"user_b\":pair[1]}\n",
    "            edge_pairs.append(pair_dict)\n",
    "\n",
    "end_at = time.time()\n",
    "print(\"--- total of edges: {:,} ---\".format(len(edge_pairs)))\n",
    "print(\"--- time cost: {:.2f}s ---\".format(end_at - start_at))\n",
    "\n",
    "edges_df = pd.DataFrame(edge_pairs)\n",
    "edges_df.to_csv(os.path.join(_OUTPUT_DIR, 'gplus_edges.csv'), sep=',', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
