{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop learning_wrapper algorithm\n",
    "\n",
    "Utilize the combinations of UserBatch (class) and learning_dist_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pseudocode active weighting vector learning algorithm]\n",
    "*step 1*: compute the aggregate distance information with argument of weighting vector [w]:\n",
    "        a. sum of weighted distances of friends\n",
    "        b. sum of weighted distances of non-friends\n",
    "                               \n",
    "*step 2*: argmin( [w] ) = sum(distances of same class) / sum(distances of different classes)\n",
    " \n",
    "*step 3*: test hypothesis that location difference between friend-distance distribution\n",
    "        vs. non-friend distance per user\n",
    "                               \n",
    "*step 4*: group users based on the previous test (paramer: distribution type, compared non-friend sample size):\n",
    "        a. a user is assigned to group 1, if its two-type distance distributions location\n",
    "           are significantly different;\n",
    "        b. a user is assigned to group 2, if its two-type distance distributions location\n",
    "           are not significantly different.\n",
    "               \n",
    "*step 5*: apply the 1-4 steps on users of group 1, split users of this group into: group 1 (with siganificant\n",
    "        difference) and group 3 (with insignificant difference);\n",
    "        Similiarly, apply 1-4 steps on users of group 2, split users of this group into: group 2 (with significant\n",
    "        difference) and group 3 (with insignificant diference).\n",
    " \n",
    "*step 6*: repeat 5th step until the stoping threshold is met:\n",
    "        a. fixed iteration, or;\n",
    "        b. insubstantial change in either weighting vector, or;\n",
    "        c. insubstantial change in members in group 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the simulate data sets, the frienships were generated based on \"hand-shaking\" protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/sim_data_yi/\" \n",
    "\n",
    "users_df   = pd.read_csv(DATA_PATH + \"users_profile.csv\", header = 0, sep = \",\")\n",
    "friends_df = pd.read_csv(DATA_PATH + \"friendships.csv\", header = 0, sep = \",\")\n",
    "dist_df    = pd.read_csv(DATA_PATH + \"dist_mat.csv\", header = 0, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>uid_a</th>\n",
       "      <th>uid_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair  uid_a  uid_b\n",
       "1  (0, 2)      0      2\n",
       "3  (0, 4)      0      4\n",
       "4  (0, 5)      0      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## friends_df is processed\n",
    "## a. create a new column to denote the user pair\n",
    "## b. exclude user-pair of non-friends\n",
    "## c. drop the 'isFriend' columns\n",
    "friends_df = friends_df[friends_df.isFriend == 1]\n",
    "friends_df[\"pair\"] = friends_df[[\"uid_a\", \"uid_b\"]].apply(lambda x: (int(x[0]), int(x[1])), axis=1)\n",
    "friends_df.drop(\"isFriend\", axis=1, inplace=True)\n",
    "friends_df = friends_df[[\"pair\", \"uid_a\", \"uid_b\"]]\n",
    "friends_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 28.0377209187 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<learning_dist_metrics.ldm.LDM at 0x7fbe38fe0a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]\n",
    "\n",
    "## subset users data to retain profile only\n",
    "profile_df = users_df[[\"ID\"] + cols]\n",
    "\n",
    "ldm = LDM()\n",
    "ldm.fit(users_df[cols], friends_df.pair.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39, 0.61, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "all_user_ids = list(set(users_df.ID))\n",
    "the_weights = ldm.get_transform_matrix()\n",
    "print the_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning wrapper functions\n",
    "* user_grouped_dist()\n",
    "* user_dist_kstest()\n",
    "* users_filter_by_weights()\n",
    "* ldm_train_with_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_grouped_dist(user_id, weights, profile_df, friends_df):\n",
    "    \"\"\" Calculate distances between a user and whose friends\n",
    "        and distance between a user and whose non-friends.\n",
    "        The groupped distance vector will be output.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * user_id: {integer}, the target user's ID\n",
    "        * weights: {vector-like, float}, the vector of feature weights which\n",
    "            is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "        * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "            with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "        * friends_df: {matrix-like, pandas.DataFrame}, pandas.DataFrame store\n",
    "            pair of user ID(s) to represent connections with columns:\n",
    "            [\"uid_a\", \"uid_b\"]\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        res: {list, list of integers}, a list of two lists, which store the distances\n",
    "            of either friends and non-friends separately.\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "        profile_df = users_df[ [\"ID\"] + cols ]\n",
    "        user_dist = user_grouped_dist(user_id = 0, weights = weights\n",
    "            , profile_df, friends_df)\n",
    "        print user_dist[\"friends\"]\n",
    "        print user_dist[\"nonfriends\"]\n",
    "    \"\"\"\n",
    "    cols = [col for col in profile_df.columns if col is not \"ID\"]\n",
    "    # get the user profile information of the target users\n",
    "    user_profile = profile_df.ix[profile_df.ID == user_id, cols].as_matrix()\n",
    "    # get the user_id of friends of the target user\n",
    "    friends_ls_a = friends_df[friends_df.uid_a == user_id].uid_b.as_matrix()\n",
    "    friends_ls_b = friends_df[friends_df.uid_b == user_id].uid_a.as_matrix()\n",
    "    friends_ls = list(set(friends_ls_a)) + list(set(friends_ls_b))\n",
    "    # calculate the weighted distance of friends\n",
    "    sim_dist_vec = []\n",
    "    for f_id in friends_ls:\n",
    "        friend_profile = profile_df.ix[profile_df.ID == f_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, friend_profile, weights)\n",
    "        sim_dist_vec.append(the_dist)\n",
    "    # calculate the weighted distances of non-friends\n",
    "    non_friends_ls = [ u for u in profile_df.ID if u not in friends_ls + [user_id] ]\n",
    "    diff_dist_vec = []\n",
    "    for nf_id in non_friends_ls:\n",
    "        nonfriend_profile = profile_df.ix[profile_df.ID == nf_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, nonfriend_profile, weights)\n",
    "        diff_dist_vec.append(the_dist)\n",
    "\n",
    "    res = [sim_dist_vec, diff_dist_vec]\n",
    "    return res\n",
    "\n",
    "\n",
    "def user_dist_kstest(sim_dist_vec, diff_dist_vec):\n",
    "    \"\"\" Test the goodness of a given weights to defferentiate friend distance\n",
    "        distributions and non-friend distance distributions of a given user.\n",
    "        The distance distribution is considered to follow Rayleigh distribution.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * sim_dist_vec: {vector-like (list), float}: distances between friends\n",
    "            and the user\n",
    "        * diff_dist_vec: {vector-like (list), float}: distances between non-friends\n",
    "            and the user\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        * res: {float}: p-value of ks-test with assumption that distances follow\n",
    "            Rayleigh distribution.\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        pval = user_dist_kstest(sim_dist_vec, diff_dist_vec)\n",
    "    \"\"\"\n",
    "    _n = 100\n",
    "    friend_param = rayleigh.fit(sim_dist_vec)\n",
    "    nonfriend_param = rayleigh.fit(diff_dist_vec)\n",
    "\n",
    "    samp_friend = rayleigh.rvs(friend_param[0], friend_param[1], _n)\n",
    "    samp_nonfriend = rayleigh.rvs(nonfriend_param[0], nonfriend_param[1], _n)\n",
    "\n",
    "    ## ouput p-value of ks-test\n",
    "    res = ks_2samp(samp_friend, samp_nonfriend)[1]\n",
    "    return res\n",
    "\n",
    "\n",
    "def users_filter_by_weights(weights, profile_df, friends_df,\n",
    "                            pval_threshold=0.20, min_friend_cnt=10):\n",
    "    \"\"\" Split a list of users into two groups, \"good fit group\"(reject) and\n",
    "        \"invalid group\", with respect to the ks-test on the null hypothesis\n",
    "        that friends' weighted distance is not significantly different from the\n",
    "        couterpart of non-friends. Assume the weighted distances of each group\n",
    "        follow Rayleigh distribution.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * weights: {vector-like, float}, the vector of feature weights which\n",
    "            is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "        * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "            with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "        * friends_df: {matrix-like, pandas.DataFrame}, pandas.DataFrame store\n",
    "            pair of user ID(s) to represent connections with columns:\n",
    "            [\"uid_a\", \"uid_b\"]\n",
    "        * pval_threshold: {float}, the threshold for p-value to reject hypothesis\n",
    "        * min_friend_cnt: {integer}, drop users whose total of friends is less\n",
    "            than this minimum count\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        res: {list} grouped list of user ids\n",
    "           res[0] stores all users whose null hypothesis does not holds\n",
    "           res[1] stores all users whose null hypothesis hold\n",
    "           null hypothesis, given weights, distance distribution of all friends\n",
    "           is significantly different from distance distribution of all non-fri\n",
    "           -ends\n",
    "\n",
    "        Examples:\n",
    "        --------\n",
    "        weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "        profile_df = users_df[[\"ID\", cols]]\n",
    "        grouped_users = users_filter_by_weights(weights,\n",
    "                            profile_df, friends_df,\n",
    "                            pval_threshold = 0.10, min_friend_cnt = 10)\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        min_friend_cnt is not implemented\n",
    "    \"\"\"\n",
    "\n",
    "    all_users_ids = list(set(profile_df.ID))\n",
    "    # container for users meeting different critiria\n",
    "    good_fits = []\n",
    "    bad_fits = []\n",
    "    for uid in all_users_ids:\n",
    "        res_dists = user_grouped_dist(uid, weights, profile_df, friends_df)\n",
    "        pval = user_dist_kstest(res_dists[0], res_dists[1])\n",
    "        if pval <= pval_threshold:\n",
    "            good_fits.append(uid)\n",
    "        else:\n",
    "            bad_fits.append(uid)\n",
    "\n",
    "    res = [good_fits, bad_fits]\n",
    "    return res\n",
    "\n",
    "def user_grouped_dist(user_id, weights, profile_df, friends_df):\n",
    "    \"\"\" Calculate distances between a user and whose friends\n",
    "        and distance between a user and whose non-friends.\n",
    "        The groupped distance vector will be output.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * user_id: {integer}, the target user's ID\n",
    "        * weights: {vector-like, float}, the vector of feature weights which\n",
    "            is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "        * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "            with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "        * friends_df: {matrix-like, pandas.DataFrame}, pandas.DataFrame store\n",
    "            pair of user ID(s) to represent connections with columns:\n",
    "            [\"uid_a\", \"uid_b\"]\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        res: {list, list of integers}, a list of two lists, which store the distances\n",
    "            of either friends and non-friends separately.\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "        profile_df = users_df[ [\"ID\"] + cols ]\n",
    "        user_dist = user_grouped_dist(user_id = 0, weights = weights\n",
    "            , profile_df, friends_df)\n",
    "        print user_dist[\"friends\"]\n",
    "        print user_dist[\"nonfriends\"]\n",
    "    \"\"\"\n",
    "    cols = [col for col in profile_df.columns if col is not \"ID\"]\n",
    "    # get the user profile information of the target users\n",
    "    user_profile = profile_df.ix[profile_df.ID == user_id, cols].as_matrix()\n",
    "    # get the user_id of friends of the target user\n",
    "    friends_ls_a = friends_df[friends_df.uid_a == user_id].uid_b.as_matrix()\n",
    "    friends_ls_b = friends_df[friends_df.uid_b == user_id].uid_a.as_matrix()\n",
    "    friends_ls = list(set(friends_ls_a)) + list(set(friends_ls_b))\n",
    "    # calculate the weighted distance of friends\n",
    "    sim_dist_vec = []\n",
    "    for f_id in friends_ls:\n",
    "        friend_profile = profile_df.ix[profile_df.ID == f_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, friend_profile, weights)\n",
    "        sim_dist_vec.append(the_dist)\n",
    "    # calculate the weighted distances of non-friends\n",
    "    non_friends_ls = [ u for u in profile_df.ID if u not in friends_ls + [user_id] ]\n",
    "    diff_dist_vec = []\n",
    "    for nf_id in non_friends_ls:\n",
    "        nonfriend_profile = profile_df.ix[profile_df.ID == nf_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, nonfriend_profile, weights)\n",
    "        diff_dist_vec.append(the_dist)\n",
    "\n",
    "    res = [sim_dist_vec, diff_dist_vec]\n",
    "    return res\n",
    "\n",
    "\n",
    "def user_dist_kstest(sim_dist_vec, diff_dist_vec):\n",
    "    \"\"\" Test the goodness of a given weights to defferentiate friend distance\n",
    "        distributions and non-friend distance distributions of a given user.\n",
    "        The distance distribution is considered to follow Rayleigh distribution.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * sim_dist_vec: {vector-like (list), float}: distances between friends\n",
    "            and the user\n",
    "        * diff_dist_vec: {vector-like (list), float}: distances between non-friends\n",
    "            and the user\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        * res: {float}: p-value of ks-test with assumption that distances follow\n",
    "            Rayleigh distribution.\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        pval = user_dist_kstest(sim_dist_vec, diff_dist_vec)\n",
    "    \"\"\"\n",
    "    _n = 100\n",
    "    friend_param = rayleigh.fit(sim_dist_vec)\n",
    "    nonfriend_param = rayleigh.fit(diff_dist_vec)\n",
    "\n",
    "    samp_friend = rayleigh.rvs(friend_param[0], friend_param[1], _n)\n",
    "    samp_nonfriend = rayleigh.rvs(nonfriend_param[0], nonfriend_param[1], _n)\n",
    "\n",
    "    ## ouput p-value of ks-test\n",
    "    res = ks_2samp(samp_friend, samp_nonfriend)[1]\n",
    "    return res\n",
    "\n",
    "\n",
    "def users_filter_by_weights(weights, users_list,\n",
    "                            profile_df, friends_df,\n",
    "                            pval_threshold=0.20, min_friend_cnt=10):\n",
    "    \"\"\" Split a list of users into two groups, \"good fit group\"(reject) and\n",
    "        \"invalid group\", with respect to the ks-test on the null hypothesis\n",
    "        that friends' weighted distance is not significantly different from the\n",
    "        couterpart of non-friends. Assume the weighted distances of each group\n",
    "        follow Rayleigh distribution.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        * weights: {vector-like, float}, the vector of feature weights which\n",
    "            is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "        * users_list: {vector-like, integer}, the list of user id\n",
    "        * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "            with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "        * friends_df: {matrix-like, pandas.DataFrame}, pandas.DataFrame store\n",
    "            pair of user ID(s) to represent connections with columns:\n",
    "            [\"uid_a\", \"uid_b\"]\n",
    "        * pval_threshold: {float}, the threshold for p-value to reject hypothesis\n",
    "        * min_friend_cnt: {integer}, drop users whose total of friends is less\n",
    "            than this minimum count\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        res: {list} grouped list of user ids\n",
    "           res[0] stores all users whose null hypothesis does not holds\n",
    "           res[1] stores all users whose null hypothesis hold\n",
    "           null hypothesis, given weights, distance distribution of all friends\n",
    "           is significantly different from distance distribution of all non-fri\n",
    "           -ends\n",
    "\n",
    "        Examples:\n",
    "        --------\n",
    "        weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "        profile_df = users_df[[\"ID\", cols]]\n",
    "        grouped_users = users_filter_by_weights(weights,\n",
    "                            profile_df, friends_df,\n",
    "                            pval_threshold = 0.10, min_friend_cnt = 10)\n",
    "\n",
    "        Notes:\n",
    "        -----\n",
    "        min_friend_cnt is not implemented\n",
    "    \"\"\"\n",
    "    #all_users_ids = list(set(profile_df.ID))\n",
    "    users_list\n",
    "    # container for users meeting different critiria\n",
    "    good_fits = []\n",
    "    bad_fits = []\n",
    "    for uid in users_list:\n",
    "        res_dists = user_grouped_dist(uid, weights, profile_df, friends_df)\n",
    "        pval = user_dist_kstest(res_dists[0], res_dists[1])\n",
    "        if pval <= pval_threshold:\n",
    "            good_fits.append(uid)\n",
    "        else:\n",
    "            bad_fits.append(uid)\n",
    "\n",
    "    res = [good_fits, bad_fits]\n",
    "    return res\n",
    "\n",
    "def ldm_train_with_list(users_list,\n",
    "                        profile_df, friends_df,\n",
    "                        retain_type=0):\n",
    "    \"\"\" learning distance matrics with ldm() instance, provided\n",
    "        with selected list of users.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        * users_list: {vector-like, integer}, the list of user id\n",
    "        * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "            with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "        * friends_df: {matrix-like, pandas.DataFrame}, pandas.DataFrame store\n",
    "            pair of user ID(s) to represent connections with columns:\n",
    "            [\"uid_a\", \"uid_b\"]\n",
    "        * retain_type: {integer}, 0, adopting 'or' logic by keeping relation\n",
    "            -ship in friends_df if either of entities is in user_list\n",
    "            1, adopting 'and' logic\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        res: {vector-like, float}, output of ldm.get_transform_matrix()\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        new_dist_metrics = ldm_train_with_list(user_list,\n",
    "                                               profile_df,\n",
    "                                               friends_df)\n",
    "    \"\"\"\n",
    "    ldm = LDM()\n",
    "    if retain_type == 0:\n",
    "        friends_df = friends_df.ix[friends_df.uid_a.isin(users_list) |\n",
    "                                   friends_df.uid_b.isin(users_list)]\n",
    "    else:\n",
    "        friends_df = friends_df.ix[friends_df.uid_a.isin(users_list) &\n",
    "                                   friends_df.uid_b.isin(users_list)]\n",
    "\n",
    "    cols = profile_df.columns.drop(\"ID\")\n",
    "    ldm.fit(profile_df[cols], friends_df.pair.as_matrix())\n",
    "    return ldm.get_transform_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will simulate the iterative learning process by run the line in a manual fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of memebers in group 0: 42, # of memebers in group 1: 58\n"
     ]
    }
   ],
   "source": [
    "all_users_ids = list(set(profile_df.ID))\n",
    "g0, g1 = users_filter_by_weights(the_weights, all_users_ids, profile_df, friends_df, 0.20, 10)\n",
    "print \"# of memebers in group 0: %d, # of memebers in group 1: %d\" % (len(g0), len(g1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st round learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 28.6584019661 seconds ---\n",
      "--- 43.3099880219 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.36, 0.6, 0.0, 0.04, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.41, 0.59, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "## define the data utilization type\n",
    "RETAIN_TYPE = 0\n",
    "\n",
    "g0_dist = ldm_train_with_list(g0, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "g1_dist = ldm_train_with_list(g1, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "\n",
    "print \"Group 0's learned distance metrics:\"\n",
    "print g0_dist\n",
    "\n",
    "print \"Group 1's learned distance metrics:\"\n",
    "print g1_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of good fits: 29, # of bad fits: 13\n"
     ]
    }
   ],
   "source": [
    "# split members in group 0 by the learning dist metrics\n",
    "g0_good, g0_bad = users_filter_by_weights(g0_dist, g0, profile_df, friends_df, 0.20, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g0_good), len(g0_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of good fits: 24, # of bad fits: 34\n"
     ]
    }
   ],
   "source": [
    "g1_good, g1_bad = users_filter_by_weights(g1_dist, g1, profile_df, friends_df, 0.20, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g1_good), len(g1_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of memebers in group 0: 63, # of memebers in group 1: 37\n"
     ]
    }
   ],
   "source": [
    "g0 = g0_good + g1_bad\n",
    "g1 = g0_bad + g1_good\n",
    "print \"# of memebers in group 0: %d, # of memebers in group 1: %d\" % (len(g0), len(g1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd round learning (p-value: 0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 40.4158170223 seconds ---\n",
      "--- 28.6820819378 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.43, 0.56, 0.0, 0.0, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.32, 0.67, 0.0, 0.01, 0.0, 0.0]\n",
      " ----------------------------------------------\n",
      "# of good fits: 20, # of bad fits: 30\n",
      "# of good fits: 16, # of bad fits: 34\n",
      " ----------------------------------------------\n",
      "# of memebers in group 0: 54, # of memebers in group 1: 46\n"
     ]
    }
   ],
   "source": [
    "pval = 0.19\n",
    "\n",
    "g0_dist = ldm_train_with_list(g0, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "g1_dist = ldm_train_with_list(g1, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "\n",
    "print \"Group 0's learned distance metrics:\"\n",
    "print g0_dist\n",
    "\n",
    "print \"Group 1's learned distance metrics:\"\n",
    "print g1_dist\n",
    "\n",
    "print \" ----------------------------------------------\"\n",
    "\n",
    "g0_good, g0_bad = users_filter_by_weights(g0_dist, g0, profile_df, friends_df, pval, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g0_good), len(g0_bad))\n",
    "\n",
    "g1_good, g1_bad = users_filter_by_weights(g1_dist, g1, profile_df, friends_df, pval, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g1_good), len(g1_bad))\n",
    "\n",
    "print \" ----------------------------------------------\"\n",
    "g0 = g0_good + g1_bad\n",
    "g1 = g0_bad + g1_good\n",
    "print \"# of memebers in group 0: %d, # of memebers in group 1: %d\" % (len(g0), len(g1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd round learning (p-value: 0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 34.8061089516 seconds ---\n",
      "--- 32.257942915 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.34, 0.65, 0.0, 0.0, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.46, 0.53, 0.0, 0.01, 0.0, 0.0]\n",
      " ----------------------------------------------\n",
      "# of good fits: 18, # of bad fits: 36\n",
      "# of good fits: 13, # of bad fits: 33\n",
      " ----------------------------------------------\n",
      "# of memebers in group 0: 51, # of memebers in group 1: 49\n"
     ]
    }
   ],
   "source": [
    "pval = 0.18\n",
    "\n",
    "g0_dist = ldm_train_with_list(g0, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "g1_dist = ldm_train_with_list(g1, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "\n",
    "print \"Group 0's learned distance metrics:\"\n",
    "print g0_dist\n",
    "\n",
    "print \"Group 1's learned distance metrics:\"\n",
    "print g1_dist\n",
    "\n",
    "print \" ----------------------------------------------\"\n",
    "\n",
    "g0_good, g0_bad = users_filter_by_weights(g0_dist, g0, profile_df, friends_df, pval, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g0_good), len(g0_bad))\n",
    "\n",
    "g1_good, g1_bad = users_filter_by_weights(g1_dist, g1, profile_df, friends_df, pval, 10)\n",
    "print \"# of good fits: %d, # of bad fits: %d\" % (len(g1_good), len(g1_bad))\n",
    "\n",
    "print \" ----------------------------------------------\"\n",
    "g0 = g0_good + g1_bad\n",
    "g1 = g0_bad + g1_good\n",
    "print \"# of memebers in group 0: %d, # of memebers in group 1: %d\" % (len(g0), len(g1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## max_iteration, fixed pvalue = 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- 1 iteration --------\n",
      "--- 33.1917309761 seconds ---\n",
      "--- 28.4636030197 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.45, 0.55, 0.0, 0.0, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.32, 0.68, 0.0, 0.0, 0.0, 0.0]\n",
      " ---------------------------------------------- \n",
      "# of good fits: 26, # of bad fits: 31\n",
      "# of good fits: 18, # of bad fits: 25\n",
      " ---------------------------------------------- \n",
      "# of memebers in group 0: 51, # of memebers in group 1: 49\n",
      " ---------------------------------------------- \n",
      "------- 2 iteration --------\n",
      "--- 27.7973771095 seconds ---\n",
      "--- 35.2376430035 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.51, 0.48, 0.0, 0.01, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.32, 0.68, 0.0, 0.0, 0.0, 0.0]\n",
      " ---------------------------------------------- \n",
      "# of good fits: 20, # of bad fits: 31\n",
      "# of good fits: 19, # of bad fits: 30\n",
      " ---------------------------------------------- \n",
      "# of memebers in group 0: 50, # of memebers in group 1: 50\n",
      " ---------------------------------------------- \n",
      "------- 3 iteration --------\n",
      "--- 25.4890210629 seconds ---\n",
      "--- 33.3930261135 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.42, 0.58, 0.0, 0.0, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.44, 0.54, 0.0, 0.01, 0.0, 0.0]\n",
      " ---------------------------------------------- \n",
      "# of good fits: 20, # of bad fits: 30\n",
      "# of good fits: 22, # of bad fits: 28\n",
      " ---------------------------------------------- \n",
      "# of memebers in group 0: 48, # of memebers in group 1: 52\n",
      " ---------------------------------------------- \n",
      "------- 4 iteration --------\n",
      "--- 36.1811540127 seconds ---\n",
      "--- 25.9866290092 seconds ---\n",
      "Group 0's learned distance metrics:\n",
      "[0.42, 0.58, 0.0, 0.0, 0.0, 0.0]\n",
      "Group 1's learned distance metrics:\n",
      "[0.38, 0.62, 0.0, 0.0, 0.0, 0.0]\n",
      " ---------------------------------------------- \n",
      "# of good fits: 25, # of bad fits: 23"
     ]
    }
   ],
   "source": [
    "# learning parameter\n",
    "RETAIN_TYPE = 0\n",
    "PVAL = 0.20\n",
    "MIN_FRIENDS = 10 # not implemented in function\n",
    "# hyper-parameter\n",
    "max_iters = 10\n",
    "# process controller\n",
    "counter = 0\n",
    "\n",
    "while counter < max_iters:\n",
    "    counter += 1\n",
    "    print \"------- %d iteration --------\" % counter\n",
    "    g0_dist = ldm_train_with_list(g0, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "    g1_dist = ldm_train_with_list(g1, profile_df, friends_df, retain_type=RETAIN_TYPE)\n",
    "    print \"Group 0's learned distance metrics:\"\n",
    "    print g0_dist\n",
    "    print \"Group 1's learned distance metrics:\"\n",
    "    print g1_dist\n",
    "\n",
    "    print \"---------------------------------------------- \"\n",
    "    g0_good, g0_bad = users_filter_by_weights(g0_dist, g0, profile_df, friends_df, PVAL, 10)\n",
    "    print \"# of good fits: %d, # of bad fits: %d\" % (len(g0_good), len(g0_bad))\n",
    "    g1_good, g1_bad = users_filter_by_weights(g1_dist, g1, profile_df, friends_df, PVAL, 10)\n",
    "    print \"# of good fits: %d, # of bad fits: %d\" % (len(g1_good), len(g1_bad))\n",
    "\n",
    "    print \"---------------------------------------------- \"\n",
    "    g0 = g0_good + g1_bad\n",
    "    g1 = g0_bad + g1_good\n",
    "    print \"# of memebers in group 0: %d, # of memebers in group 1: %d\" % (len(g0), len(g1)) \n",
    "    print \"---------------------------------------------- \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
