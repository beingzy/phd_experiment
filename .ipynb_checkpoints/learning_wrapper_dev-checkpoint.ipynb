{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Structure\n",
    "* k: # of groups, or # of containers\n",
    "* one buffer\n",
    "* a member in buffer will be examined against all of newly learned distrance, all quantified distance metrics will be ranked by p-value in descending order. The top distance metrics is the one chosen for the user.\n",
    "* member of a container will be examined for the distance metrics learned for the population. If the member is not cosider enjoy a good fit of the distance metrics, the member will be checked with other alternative distance metris. Until at least one of qualified distance metrics found, the member is sent to the buffer.\n",
    "* overall fit is measured by the following metrics\n",
    "$$\n",
    "fs_1 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} / |U_{j}|) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "$$\n",
    "fs_2 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} / |U_{j}|^2) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "$$\n",
    "fs_3 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} \\cdot \\frac{N}{|U_{j}|^2}) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "* $u_i$: $i$th user\n",
    "* $D_j$: the distance metrics learned for $j$th user group\n",
    "* $U_j$: $j$th user group\n",
    "* $|\\cdot|$: size of users in the container\n",
    "* $C$: the parameter determines the strength of penalty for more members in the buffer\n",
    "* $N$: the total number of users in fit group, $\\sum_{j = 1}^{k} |U_{j}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from GWDLearner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" wrap up the learning iteration\n",
    "\n",
    "functions:\n",
    "----------\n",
    "a. assigning member to fitted group\n",
    "b. test members against all distance metrics rather than its previous group's\n",
    "   [(group_index, pval)]\n",
    "c. sort all \n",
    "\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "profile_df: {pandas.DataFrame}\n",
    "networkx: {networkx.Graph}\n",
    "k: {integer}, the target number of groups to learn\n",
    "min_delta_f: {float}, the minimal decrease in f score to continue learning\n",
    "\n",
    "Returns:\n",
    "--------\n",
    "\"\"\"\n",
    "def init_embed_list(n):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ls = []\n",
    "    for i in range(n):\n",
    "        ls.append([])\n",
    "    return ls\n",
    "\n",
    "def init_dict_list(k):\n",
    "    \"\"\" create dictionary with k items, each\n",
    "        item is a empty list\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for i in range(k):\n",
    "        res_dict[i] = []\n",
    "    return res_dict\n",
    "\n",
    "k = 2\n",
    "min_delta_f = 0.001\n",
    "\n",
    "dist_metrics = init_dict_list(k)\n",
    "fit_group = init_dict_list(k)\n",
    "unfit_group = init_dict_list(k)\n",
    "buffer_group = []\n",
    "fit_pvals = init_dict_list(k)\n",
    "unfit_pvals = init_dict_list(k)\n",
    "\n",
    "# results value\n",
    "fs_hist = []\n",
    "knowledge_pkg = []\n",
    "\n",
    "# *. distance has been learned\n",
    "# *. group composite is inherited from the previous iteration\n",
    "\n",
    "dist_metrics = {0: [0.1, 0.3, 0.6, 0], 1: [0.5, 0.1, 0.4, 0], 2: [0.25, 0.25, 0.25, 0.25]}\n",
    "fit_group = {0:[1, 2, 4, 5], 1:[3, 6, 7], 2:[8, 9]}\n",
    "fit_pvals = {0:[0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
    "buffer_group = [10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455982544991\n",
      "0.159170097104\n",
      "0.021229649556\n",
      "0.402326857032\n",
      "0.719825281428\n",
      "0.703303912418\n",
      "0.798114006163\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae62aa7eff24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpval\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfit_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0munfit_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# examine user aginst the group distance metrics\n",
    "# retain members bearing fit\n",
    "# reassign users to unfit_group\n",
    "for i, g in fit_group.iteritems():\n",
    "    for j, u in enumerate(g):\n",
    "        # print \"(%d, %d)\" % (i, u)\n",
    "        pval = np.random.uniform(0, 1, 1)[0]\n",
    "        print pval\n",
    "        if pval > 0.5:\n",
    "            fit_group[i].remove(u)\n",
    "            unfit_group[i].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5]\n",
      "[6]\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "for i, g in fit_group.iteritems():\n",
    "    print g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-acbec203632c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# unfit_group\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcomp_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdist_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mcomp_dist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "# fit_group\n",
    "# unfit_group\n",
    "for i, g in enumerate(fit_group):\n",
    "    comp_dist = dist_metrics[:i] + dist_metrics[(i + 1):]\n",
    "    for j, u in enumerate(g):\n",
    "        print comp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_fit_group(uid, dist_metrics, threshold,  current_group = []):\n",
    "    \"\"\" calculate user p-value for the distance metrics of\n",
    "        each group\n",
    "        \n",
    "    Parameters:\n",
    "    ----------\n",
    "    uid: {integer}, user id\n",
    "    current_group: {integer}, group index\n",
    "    dist_metrics: {dictionary}, all {index: distance_metrics}\n",
    "    threshold: {float}, threshold for qualifying pvalue of ks-test\n",
    "    \n",
    "    Resutls:\n",
    "    --------\n",
    "    res: {list}, [group_idx, pvalue]\n",
    "    \"\"\"\n",
    "    if current_group == []:\n",
    "        other_group = dist_metrics.keys()\n",
    "        other_dist_metrics = dist_metrics.values()\n",
    "    else:\n",
    "        other_group = [i for i in dist_metrics.keys() if i != current_group]\n",
    "        other_dist_metrics = [d for g, d in dist_metrics.iteritems() if g != current_group]\n",
    "    \n",
    "    pvals = []\n",
    "\n",
    "    for d in other_dist_metrics:\n",
    "        # loop through all distance metrics and calculate\n",
    "        # p-value of ks-test by applying it to the user\n",
    "        # relationships\n",
    "        # sdist, ddist = user_grouped_dist(user_id = uid, weights=dist_metrics, *profile_df{DataFramw, ID}*,\n",
    "        #                   *friends_networkx*)\n",
    "        # pval = user_dist_kstest(sim_dist_vec=sdist, diff_dist_vec=ddist, fit_rayleigh=True, _n=1000)\n",
    "        pval = np.random.uniform(0, 1, 1)\n",
    "        pvals.append(pval)\n",
    "        \n",
    "    min_pval = min(pvals)[0]\n",
    "    min_index = [i for i, p in enumerate(pvals) if p == min_pval][0]\n",
    "    best_group = other_group[min_index]\n",
    "    \n",
    "    if min_pval >= threshold:\n",
    "        # if min_pval >= threshold, user is not considered \n",
    "        # to have a good fit by any of distance metrics\n",
    "        best_group = None\n",
    "        min_pval = None\n",
    "    \n",
    "    return (best_group, min_pval)\n",
    "\n",
    "def get_fit_score(fit_pvals, buffer_group, c, t=2):\n",
    "    \"\"\" calculate the fit score given the member composite\n",
    "        and its pvalues with its group distance metrics, with\n",
    "        c determinng the strength of penalty for keeping a \n",
    "        larger number of users in buffer_group\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit_pvals: {dict}, {index: [pvalues]}\n",
    "    buffer_group: {list}, [userid, ...]\n",
    "    c: {float}, \n",
    "    t: {integer} 1, 2 or 3\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fit_score: {float}, fit score, a smaller value indidcate\n",
    "                a overall better fit\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    fit_group = fit_group\n",
    "    fit_pvals = fit_pvals\n",
    "    buffer_group = buffer_group\n",
    "    c = 0.1\n",
    "    fscore = get_fit_score(fit_group, fit_pvals, buffer_group, c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted sum of pvalues \n",
    "    if t not in [1, 2, 3]:\n",
    "        raise NameError('Error: type (t) is not legal value (1 or 2)!')\n",
    "    \n",
    "    wsum_pval = 0\n",
    "    if t == 1:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v) * 1.0 / len(v))\n",
    "    if t == 2:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "    if t == 3:\n",
    "        num_users = 0\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "            num_users += len(v)\n",
    "        wsum_pval = num_users * 1.0 * wsum_pval\n",
    "\n",
    "    penalty = c * len(buffer_group)\n",
    "    fit_score = wsum_pval + penalty # smaller value indicates a better overall fit\n",
    "    \n",
    "    return fit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_metrics = {0: [0.1, 0.3, 0.6, 0], 1: [0.5, 0.1, 0.4, 0], 2: [0.25, 0.25, 0.25, 0.25]}\n",
    "fit_group = {0:[1, 2, 4, 5], 1:[3, 6, 7], 2:[8, 9]}\n",
    "unfit_group = {}\n",
    "fit_pvals = {0:[0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
    "buffer_group = []\n",
    "\n",
    "threshold = 0.5\n",
    "c = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 01: learn distance metrics\n",
    "for g, uids in fit_group.iteritems():\n",
    "    # function learn\n",
    "    dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "    dist_metrics[g] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.69091325339493581, 0.39462462263873777, 0.77585041368993457, 0.068076303465098631], 1: [0.95080137045707236, 0.63607843781284268, 0.76827558153779019, 0.44330529911623573], 2: [0.66541180898513286, 0.84420538250473498, 0.52575232197385757, 0.8991388834393661]}\n",
      "fit_group: {0: [1, 2, 4, 5], 1: [3, 6, 7], 2: [8, 9]}\n",
      "fit_pvals: {0: [0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
      "unfit_group: {}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 02: update the member composite with updated group distance metrics\n",
    "# threshold is needed to be defined\n",
    "fit_group_copy = fit_group.copy()\n",
    "for g, uids in fit_group_copy.iteritems():\n",
    "    target_dist = dist_metrics[g]\n",
    "    for uid in uids:\n",
    "        # calcualte the ks-pvalue with update distance metrics\n",
    "        # target_dist\n",
    "        pval = np.random.uniform(0, 1, 1)[0]\n",
    "        if pval >= threshold:\n",
    "            # remove the user and its information \n",
    "            # from relevant container\n",
    "            idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "            fit_group[g].pop(idx)\n",
    "            fit_pvals[g].pop(idx)\n",
    "            # add the user to the unfit_group\n",
    "            if g in unfit_group:\n",
    "                unfit_group[g].append(uid)\n",
    "            else:\n",
    "                unfit_group[g] = [uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.69091325339493581, 0.39462462263873777, 0.77585041368993457, 0.068076303465098631], 1: [0.95080137045707236, 0.63607843781284268, 0.76827558153779019, 0.44330529911623573], 2: [0.66541180898513286, 0.84420538250473498, 0.52575232197385757, 0.8991388834393661]}\n",
      "fit_group: {0: [1, 2, 5], 1: [3, 7], 2: [9]}\n",
      "fit_pvals: {0: [0.2, 0.12, 0.21], 1: [0.31, 0.17], 2: [0.05]}\n",
      "unfit_group: {0: [4], 1: [6], 2: [8]}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 03: test members in unfit_group to see\n",
    "# if it has a good fit with other distmetrics\n",
    "# make a copy of the buffer group container\n",
    "buffer_group_copy = [i for i in buffer_group]\n",
    "if len(buffer_group_copy) > 0:\n",
    "    for uid in buffer_group_copy:\n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold)\n",
    "        if not np.isnan(new_pval):\n",
    "            buffer_group.remove(uid)\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]\n",
    "                \n",
    "\n",
    "unfit_group_copy = unfit_group.copy()\n",
    "for g, uids in unfit_group_copy.iteritems():\n",
    "    for uid in uids:        \n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold, g)\n",
    "        if np.isnan(new_pval):\n",
    "            buffer_group.append(uid)\n",
    "        else:\n",
    "            unfit_group[g].remove(uid)\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.69091325339493581, 0.39462462263873777, 0.77585041368993457, 0.068076303465098631], 1: [0.95080137045707236, 0.63607843781284268, 0.76827558153779019, 0.44330529911623573], 2: [0.66541180898513286, 0.84420538250473498, 0.52575232197385757, 0.8991388834393661]}\n",
      "fit_group: {0: [1, 2, 5, 6], 1: [3, 7, 4, 8], 2: [9]}\n",
      "fit_pvals: {0: [0.2, 0.12, 0.21, 0.17646017813426129], 1: [0.31, 0.17, 0.46106789350378374, 0.44355476787721504], 2: [0.05]}\n",
      "unfit_group: {0: [], 1: [], 2: []}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572770709879\n",
      "0.18069267747\n",
      "1.62623409723\n"
     ]
    }
   ],
   "source": [
    "# step 04: calculate current fscore\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=1)\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=2)\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-530feb4b881f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#fs_hist = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#knowledge_pkg = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfs_hist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mknowledge_pkg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbest_fs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs_hist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "package = {\"dist_metrics\": dist_metrics, \n",
    "           \"fit_group\": fit_group, \n",
    "           \"buffer_group\": buffer_group}\n",
    "\n",
    "#fs_hist = []\n",
    "#knowledge_pkg = []\n",
    "fs_hist.append(fs)\n",
    "knowledge_pkg.append(package)\n",
    "best_fs = min(fs_hist)\n",
    "\n",
    "if best_fs - fs <= min_delta_f:\n",
    "    # _no_imp_counter defined prior to while()\n",
    "    # while(_no_imp_counter < max_iter):\n",
    "    _no_imp_counter += _no_imp_counter \n",
    "else:\n",
    "    _no_imp_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop the iteractive learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_uids = range(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_loop_counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration is in processing ...\n",
      "1) #fit: 12, #unfit: 8, #buffer: 0\n",
      "2) #fit: 12, #unfit: 8, #buffer: 0\n",
      "3) #fit: 15, #unfit: 5, #buffer: 3\n",
      "2 iteration is in processing ...\n",
      "1) #fit: 9, #unfit: 11, #buffer: 3\n",
      "2) #fit: 11, #unfit: 11, #buffer: 1\n",
      "3) #fit: 14, #unfit: 8, #buffer: 6\n",
      "3 iteration is in processing ...\n",
      "1) #fit: 9, #unfit: 13, #buffer: 6\n",
      "2) #fit: 14, #unfit: 13, #buffer: 1\n",
      "3) #fit: 18, #unfit: 9, #buffer: 7\n",
      "4 iteration is in processing ...\n",
      "1) #fit: 9, #unfit: 18, #buffer: 7\n",
      "2) #fit: 13, #unfit: 18, #buffer: 3\n",
      "3) #fit: 18, #unfit: 13, #buffer: 11\n",
      "5 iteration is in processing ...\n",
      "1) #fit: 14, #unfit: 17, #buffer: 11\n",
      "2) #fit: 22, #unfit: 17, #buffer: 3\n",
      "3) #fit: 27, #unfit: 12, #buffer: 11\n",
      "6 iteration is in processing ...\n",
      "1) #fit: 18, #unfit: 21, #buffer: 11\n",
      "2) #fit: 27, #unfit: 21, #buffer: 2\n",
      "3) #fit: 35, #unfit: 13, #buffer: 7\n",
      "7 iteration is in processing ...\n",
      "1) #fit: 27, #unfit: 21, #buffer: 7\n",
      "2) #fit: 32, #unfit: 21, #buffer: 2\n",
      "3) #fit: 40, #unfit: 13, #buffer: 9\n",
      "8 iteration is in processing ...\n",
      "1) #fit: 26, #unfit: 27, #buffer: 9\n",
      "2) #fit: 32, #unfit: 27, #buffer: 3\n",
      "3) #fit: 40, #unfit: 19, #buffer: 15\n",
      "9 iteration is in processing ...\n",
      "1) #fit: 27, #unfit: 32, #buffer: 15\n",
      "2) #fit: 41, #unfit: 32, #buffer: 1\n",
      "3) #fit: 52, #unfit: 21, #buffer: 12\n",
      "10 iteration is in processing ...\n",
      "1) #fit: 35, #unfit: 38, #buffer: 12\n",
      "2) #fit: 43, #unfit: 38, #buffer: 4\n",
      "3) #fit: 56, #unfit: 25, #buffer: 16\n",
      "11 iteration is in processing ...\n",
      "1) #fit: 35, #unfit: 46, #buffer: 16\n",
      "2) #fit: 47, #unfit: 46, #buffer: 4\n",
      "3) #fit: 63, #unfit: 30, #buffer: 18\n",
      "12 iteration is in processing ...\n",
      "1) #fit: 45, #unfit: 48, #buffer: 18\n",
      "2) #fit: 59, #unfit: 48, #buffer: 4\n",
      "3) #fit: 74, #unfit: 33, #buffer: 23\n",
      "13 iteration is in processing ...\n",
      "1) #fit: 54, #unfit: 53, #buffer: 23\n",
      "2) #fit: 71, #unfit: 53, #buffer: 6\n",
      "3) #fit: 91, #unfit: 33, #buffer: 19\n",
      "14 iteration is in processing ...\n",
      "1) #fit: 66, #unfit: 58, #buffer: 19\n",
      "2) #fit: 81, #unfit: 58, #buffer: 4\n",
      "3) #fit: 103, #unfit: 36, #buffer: 19\n",
      "15 iteration is in processing ...\n",
      "1) #fit: 66, #unfit: 73, #buffer: 19\n",
      "2) #fit: 76, #unfit: 73, #buffer: 9\n",
      "3) #fit: 97, #unfit: 52, #buffer: 40\n",
      "16 iteration is in processing ...\n",
      "1) #fit: 64, #unfit: 85, #buffer: 40\n",
      "2) #fit: 91, #unfit: 85, #buffer: 13\n",
      "3) #fit: 122, #unfit: 54, #buffer: 37\n",
      "17 iteration is in processing ...\n",
      "1) #fit: 82, #unfit: 94, #buffer: 37\n",
      "2) #fit: 109, #unfit: 94, #buffer: 10\n",
      "3) #fit: 144, #unfit: 59, #buffer: 34\n",
      "18 iteration is in processing ...\n",
      "1) #fit: 101, #unfit: 102, #buffer: 34\n",
      "2) #fit: 128, #unfit: 102, #buffer: 7\n",
      "3) #fit: 161, #unfit: 69, #buffer: 44\n",
      "19 iteration is in processing ...\n",
      "1) #fit: 113, #unfit: 117, #buffer: 44\n",
      "2) #fit: 144, #unfit: 117, #buffer: 13\n",
      "3) #fit: 180, #unfit: 81, #buffer: 59\n",
      "20 iteration is in processing ...\n",
      "1) #fit: 119, #unfit: 142, #buffer: 59\n",
      "2) #fit: 163, #unfit: 142, #buffer: 15\n",
      "3) #fit: 208, #unfit: 97, #buffer: 67\n",
      "21 iteration is in processing ...\n",
      "1) #fit: 136, #unfit: 169, #buffer: 67\n",
      "2) #fit: 191, #unfit: 169, #buffer: 12\n",
      "3) #fit: 254, #unfit: 106, #buffer: 56\n",
      "22 iteration is in processing ...\n",
      "1) #fit: 165, #unfit: 195, #buffer: 56\n",
      "2) #fit: 207, #unfit: 195, #buffer: 14\n",
      "3) #fit: 275, #unfit: 127, #buffer: 73\n",
      "23 iteration is in processing ...\n",
      "1) #fit: 178, #unfit: 224, #buffer: 73\n",
      "2) #fit: 234, #unfit: 224, #buffer: 17\n",
      "3) #fit: 309, #unfit: 149, #buffer: 92\n",
      "24 iteration is in processing ...\n",
      "1) #fit: 208, #unfit: 250, #buffer: 92\n",
      "2) #fit: 270, #unfit: 250, #buffer: 30\n",
      "3) #fit: 356, #unfit: 164, #buffer: 109\n",
      "25 iteration is in processing ...\n",
      "1) #fit: 231, #unfit: 289, #buffer: 109\n",
      "2) #fit: 305, #unfit: 289, #buffer: 35\n",
      "3) #fit: 399, #unfit: 195, #buffer: 136\n",
      "26 iteration is in processing ...\n",
      "1) #fit: 272, #unfit: 322, #buffer: 136\n",
      "2) #fit: 372, #unfit: 322, #buffer: 36\n",
      "3) #fit: 477, #unfit: 217, #buffer: 149\n",
      "27 iteration is in processing ...\n",
      "1) #fit: 325, #unfit: 369, #buffer: 149\n",
      "2) #fit: 441, #unfit: 369, #buffer: 33\n",
      "3) #fit: 570, #unfit: 240, #buffer: 144\n",
      "28 iteration is in processing ...\n",
      "1) #fit: 378, #unfit: 432, #buffer: 144\n",
      "2) #fit: 488, #unfit: 432, #buffer: 34\n",
      "3) #fit: 633, #unfit: 287, #buffer: 176\n",
      "29 iteration is in processing ...\n",
      "1) #fit: 420, #unfit: 500, #buffer: 176\n",
      "2) #fit: 549, #unfit: 500, #buffer: 47\n",
      "3) #fit: 730, #unfit: 319, #buffer: 185\n",
      "30 iteration is in processing ...\n",
      "1) #fit: 499, #unfit: 550, #buffer: 185\n",
      "2) #fit: 636, #unfit: 550, #buffer: 48\n",
      "3) #fit: 819, #unfit: 367, #buffer: 232\n",
      "31 iteration is in processing ...\n",
      "1) #fit: 534, #unfit: 652, #buffer: 232\n",
      "2) #fit: 699, #unfit: 652, #buffer: 67\n",
      "3) #fit: 906, #unfit: 445, #buffer: 306\n",
      "32 iteration is in processing ...\n",
      "1) #fit: 618, #unfit: 733, #buffer: 306\n",
      "2) #fit: 849, #unfit: 733, #buffer: 75\n",
      "3) #fit: 1081, #unfit: 501, #buffer: 345\n",
      "33 iteration is in processing ...\n",
      "1) #fit: 721, #unfit: 861, #buffer: 345\n",
      "2) #fit: 994, #unfit: 861, #buffer: 72\n",
      "3) #fit: 1276, #unfit: 579, #buffer: 369\n",
      "34 iteration is in processing ...\n",
      "1) #fit: 849, #unfit: 1006, #buffer: 369\n",
      "2) #fit: 1115, #unfit: 1006, #buffer: 103\n",
      "3) #fit: 1451, #unfit: 670, #buffer: 438\n",
      "35 iteration is in processing ...\n",
      "1) #fit: 972, #unfit: 1149, #buffer: 438\n",
      "2) #fit: 1304, #unfit: 1149, #buffer: 106\n",
      "3) #fit: 1691, #unfit: 762, #buffer: 481\n",
      "36 iteration is in processing ...\n",
      "1) #fit: 1128, #unfit: 1325, #buffer: 481\n",
      "2) #fit: 1499, #unfit: 1325, #buffer: 110\n",
      "3) #fit: 1942, #unfit: 882, #buffer: 549\n",
      "37 iteration is in processing ...\n",
      "1) #fit: 1271, #unfit: 1553, #buffer: 549\n",
      "2) #fit: 1676, #unfit: 1553, #buffer: 144\n",
      "3) #fit: 2197, #unfit: 1032, #buffer: 655\n",
      "38 iteration is in processing ...\n",
      "1) #fit: 1461, #unfit: 1768, #buffer: 655\n",
      "2) #fit: 1954, #unfit: 1768, #buffer: 162\n",
      "3) #fit: 2539, #unfit: 1183, #buffer: 761\n",
      "39 iteration is in processing ...\n",
      "1) #fit: 1709, #unfit: 2013, #buffer: 761\n",
      "2) #fit: 2288, #unfit: 2013, #buffer: 182\n",
      "3) #fit: 2975, #unfit: 1326, #buffer: 822\n",
      "40 iteration is in processing ...\n",
      "1) #fit: 2000, #unfit: 2301, #buffer: 822\n",
      "2) #fit: 2609, #unfit: 2301, #buffer: 213\n",
      "3) #fit: 3371, #unfit: 1539, #buffer: 991\n",
      "41 iteration is in processing ...\n",
      "1) #fit: 2243, #unfit: 2667, #buffer: 991\n",
      "2) #fit: 2984, #unfit: 2667, #buffer: 250\n",
      "3) #fit: 3864, #unfit: 1787, #buffer: 1157\n",
      "42 iteration is in processing ...\n",
      "1) #fit: 2573, #unfit: 3078, #buffer: 1157\n",
      "2) #fit: 3474, #unfit: 3078, #buffer: 256\n",
      "3) #fit: 4485, #unfit: 2067, #buffer: 1313\n",
      "43 iteration is in processing ...\n",
      "1) #fit: 2981, #unfit: 3571, #buffer: 1313\n",
      "2) #fit: 3956, #unfit: 3571, #buffer: 338\n",
      "3) #fit: 5125, #unfit: 2402, #buffer: 1571\n",
      "44 iteration is in processing ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-d06e37705754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[0mfit_pvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "input info.:\n",
    "----------\n",
    "profile_df\n",
    "friend_networkx\n",
    "\n",
    "control parameters:\n",
    "-------------------\n",
    "t: fit score type\n",
    "\n",
    "tuning parameter:\n",
    "-----------------\n",
    "threshold: cutoff value for kstest\n",
    "c: regularization strength\n",
    "min_delta_f: threshold for significant improvement\n",
    "max_iter: maxmium number of trivial trial learning in a row \n",
    "\"\"\"\n",
    "# input info\n",
    "k = 2\n",
    "# user_profile\n",
    "\n",
    "# tuing parameters\n",
    "t = 2\n",
    "c = 0.1\n",
    "threshold = 0.5\n",
    "min_delta_f = 0.02\n",
    "max_iter = 10\n",
    "\n",
    "# initiate the containers:\n",
    "dist_metrics = init_dict_list(k) # distance metrics containers\n",
    "fit_group = init_dict_list(k)    # members composition in fit groups\n",
    "fit_pvals = init_dict_list(k)    # members' pvalue of KStest with their group distance metrics\n",
    "unfit_group = init_dict_list(k)  # members is not considerd fit by its group distance metrics\n",
    "unfit_pvals = init_dict_list(k)  # pvalues for members in unfit_group (maybe can be deleted)\n",
    "buffer_group = []                # members are not considered having fit\n",
    "\n",
    "# results value\n",
    "fs_hist = []       # list of fit scores in sequence (lastest one is the last)\n",
    "knowledge_pkg = [] # {index: {\"dist_metrics\", \"fit_group\", \"buffer_group\"}} \n",
    "\n",
    "# calculate the the init distance metrics\n",
    "\n",
    "# sampling is subset of users to calculate\n",
    "# the distance metrics is good method\n",
    "\n",
    "# dist_metrics: ldm() with subset of users\n",
    "# fit_group: subsets of users\n",
    "# buffer_group: useres are not sampled \n",
    "\n",
    "# provide initial composition of fit_group\n",
    "# and buffer_group for iterative learning\n",
    "# procedure\n",
    "# the even sampling strategy is implemeted\n",
    "# here, however, \n",
    "samp_size = len(all_uids) / k \n",
    "samp_sizes = [samp_size] * k\n",
    "all_uids_copy = [i for i in all_uids]\n",
    "\n",
    "# generate k groups of sample user groups\n",
    "for g, samp_size in zip(range(k), samp_sizes):\n",
    "    # draw samples and assign them to fit_group\n",
    "    samples = choice(all_uids_copy, samp_size, replace=False)\n",
    "    fit_group[g] = list(samples)\n",
    "    # remove samples from population pool\n",
    "    for uid in samples:\n",
    "        all_uids_copy.remove(uid)\n",
    "\n",
    "# initiate fit user pvals\n",
    "for g, uids in fit_group.iteritems():\n",
    "    fit_pvals[g] = [0] * len(uids)\n",
    "        \n",
    "# if len(all_uids_copy) > 0:\n",
    "#     buffer_group = all_uids_copy\n",
    "# else:\n",
    "#    buffer_group = []\n",
    "\n",
    "_no_imp_counter = 0\n",
    "_loop_counter = 0\n",
    "\n",
    "while _no_imp_counter < max_iter:\n",
    "    \n",
    "    _loop_counter += 1\n",
    "    print \"%d iteration is in processing ...\" % _loop_counter\n",
    "    # step 01: learn distance metrics\n",
    "    for g, uids in fit_group.iteritems():\n",
    "        # learn distance metrics\n",
    "        # here to update the computational mechanism\n",
    "        dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "        dist_metrics[g] = dist\n",
    "        \n",
    "    # step 02: update the member composite with updated group \n",
    "    # distance metrics threshold is needed to be defined\n",
    "    fit_group_copy = fit_group.copy()\n",
    "    for g, uids in fit_group_copy.iteritems():\n",
    "        target_dist = dist_metrics[g]\n",
    "        for uid in uids:\n",
    "            \n",
    "            # calcualte the ks-pvalue with update distance metrics\n",
    "            # target_dist\n",
    "            pval = np.random.uniform(0, 1, 1)[0] #----- update needed ------- #\n",
    "             \n",
    "            if pval >= threshold:\n",
    "                # remove the user and its information \n",
    "                # from relevant container\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_group[g].pop(idx)\n",
    "                # fit_group[g].remove(uid)\n",
    "                fit_pvals[g].pop(idx)\n",
    "                \n",
    "                # add the user to the unfit_group\n",
    "                if g in unfit_group:\n",
    "                    unfit_group[g].append(uid)\n",
    "                else:\n",
    "                    unfit_group[g] = [uid]\n",
    "            \n",
    "            else:\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_pvals[g][idx] = pval\n",
    "                \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"1) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    # step 03: test members in unfit_group to see\n",
    "    # if it has a good fit with other distmetrics\n",
    "    # make a copy of the buffer group container\n",
    "    buffer_group_copy = [i for i in buffer_group]\n",
    "    if len(buffer_group_copy) > 0:\n",
    "        for uid in buffer_group_copy:\n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, threshold)\n",
    "            if not new_group:\n",
    "                buffer_group.remove(uid)\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"2) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    unfit_group_copy = {k:[i for i in v] for k, v in unfit_group.iteritems()}\n",
    "    for g, uids in unfit_group_copy.iteritems():\n",
    "        for uid in uids:        \n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, threshold, g)\n",
    "            if np.isnan(new_pval):\n",
    "                buffer_group.append(uid)\n",
    "            else:\n",
    "                unfit_group[g].remove(uid)\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    # tot_fit_pvals = np.sum([len(p) for g, p in fit_pvals.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"3) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                        \n",
    "    # step 04: calculate fit score\n",
    "    fs = get_fit_score(fit_pvals, buffer_group, c=c, t=1)\n",
    "    fs_hist.append(fs)\n",
    "    \n",
    "    # step 05: evaluate stop criteria\n",
    "    package = {\"dist_metrics\": dist_metrics, \n",
    "               \"fit_group\": fit_group, \n",
    "               \"buffer_group\": buffer_group}\n",
    "\n",
    "    knowledge_pkg.append(package)\n",
    "    best_fs = min(fs_hist)\n",
    "\n",
    "    if best_fs - fs <= min_delta_f:\n",
    "        _no_imp_counter += _no_imp_counter \n",
    "    else:\n",
    "        _no_imp_counter = 0\n",
    "        \n",
    "    # print \"fit score (type-%d): %.3f\" % (t, fs)\n",
    "    # print \"best fit score: %.3f\" % best_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n"
     ]
    }
   ],
   "source": [
    "print set(fit_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input info\n",
    "k = 2\n",
    "# user_profile\n",
    "\n",
    "# tuing parameters\n",
    "t = 2\n",
    "c = 0.1\n",
    "threshold = 0.5\n",
    "min_delta_f = 0.02\n",
    "max_iter = 10\n",
    "\n",
    "# initiate the containers:\n",
    "dist_metrics = init_dict_list(k) # distance metrics containers\n",
    "fit_group = init_dict_list(k)    # members composition in fit groups\n",
    "fit_pvals = init_dict_list(k)    # members' pvalue of KStest with their group distance metrics\n",
    "unfit_group = init_dict_list(k)  # members is not considerd fit by its group distance metrics\n",
    "#unfit_pvals = init_dict_list(k)  # pvalues for members in unfit_group (maybe can be deleted)\n",
    "buffer_group = []                # members are not considered having fit\n",
    "\n",
    "# results value\n",
    "fs_hist = []       # list of fit scores in sequence (lastest one is the last)\n",
    "knowledge_pkg = [] # {index: {\"dist_metrics\", \"fit_group\", \"buffer_group\"}} \n",
    "\n",
    "# calculate the the init distance metrics\n",
    "\n",
    "# sampling is subset of users to calculate\n",
    "# the distance metrics is good method\n",
    "\n",
    "# dist_metrics: ldm() with subset of users\n",
    "# fit_group: subsets of users\n",
    "# buffer_group: useres are not sampled \n",
    "\n",
    "# provide initial composition of fit_group\n",
    "# and buffer_group for iterative learning\n",
    "# procedure\n",
    "# the even sampling strategy is implemeted\n",
    "# here, however, \n",
    "samp_size = len(all_uids) / k \n",
    "samp_sizes = [samp_size] * k\n",
    "all_uids_copy = [i for i in all_uids]\n",
    "\n",
    "# generate k groups of sample user groups\n",
    "for g, samp_size in zip(range(k), samp_sizes):\n",
    "    # draw samples and assign them to fit_group\n",
    "    samples = choice(all_uids_copy, samp_size, replace=False)\n",
    "    fit_group[g] = list(samples)\n",
    "    # remove samples from population pool\n",
    "    for uid in samples:\n",
    "        all_uids_copy.remove(uid)\n",
    "\n",
    "# initiate fit user pvals\n",
    "for g, uids in fit_group.iteritems():\n",
    "    fit_pvals[g] = [0] * len(uids)\n",
    "        \n",
    "# if len(all_uids_copy) > 0:\n",
    "#     buffer_group = all_uids_copy\n",
    "# else:\n",
    "#    buffer_group = []\n",
    "\n",
    "_no_imp_counter = 0\n",
    "_loop_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iteration is in processing ...\n",
      "1) #fit: 9, #unfit: 11, #buffer: 0\n",
      "2) #fit: 9, #unfit: 11, #buffer: 0\n"
     ]
    }
   ],
   "source": [
    "print \"%d iteration is in processing ...\" % _loop_counter\n",
    "# step 01: learn distance metrics\n",
    "for g, uids in fit_group.iteritems():\n",
    "    # learn distance metrics\n",
    "    # here to update the computational mechanism\n",
    "    dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "    dist_metrics[g] = dist\n",
    "        \n",
    "# step 02: update the member composite with updated group \n",
    "# distance metrics threshold is needed to be defined\n",
    "fit_group_copy = {k:[i for i in v] for k, v in fit_group.iteritems()}\n",
    "for g, uids in fit_group_copy.iteritems():\n",
    "    target_dist = dist_metrics[g]\n",
    "    for uid in uids:\n",
    "            \n",
    "        # calcualte the ks-pvalue with update distance metrics\n",
    "        # target_dist\n",
    "        pval = np.random.uniform(0, 1, 1)[0] #----- update needed ------- #\n",
    "             \n",
    "        if pval >= threshold:\n",
    "            # remove the user and its information \n",
    "            # from relevant container\n",
    "            idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "            fit_group[g].pop(idx)\n",
    "            fit_pvals[g].pop(idx)\n",
    "                \n",
    "            # add the user to the unfit_group\n",
    "            if g in unfit_group:\n",
    "                unfit_group[g].append(uid)\n",
    "            else:\n",
    "                unfit_group[g] = [uid]\n",
    "            \n",
    "        else:\n",
    "            idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "            fit_pvals[g][idx] = pval\n",
    "                \n",
    "tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "tot_buffer_group = len(buffer_group)\n",
    "print \"1) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "# step 03: test members in unfit_group to see\n",
    "# if it has a good fit with other distmetrics\n",
    "# make a copy of the buffer group container\n",
    "buffer_group_copy = [i for i in buffer_group]\n",
    "if len(buffer_group_copy) > 0:\n",
    "    for uid in buffer_group_copy:\n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold)\n",
    "        if not new_group:\n",
    "            buffer_group.remove(uid)\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "                    \n",
    "tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "tot_buffer_group = len(buffer_group)\n",
    "print \"2) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [17, 1, 6, 2, 18, 15, 10], 1: [12, 7, 4, 19]}\n",
      "*********************************\n",
      "group: 0, uid: 17\n",
      "group: 0, uid: 1\n",
      "group: 0, uid: 6\n",
      "group: 0, uid: 2\n",
      "group: 0, uid: 18\n",
      "group: 0, uid: 15\n",
      "group: 0, uid: 10\n",
      "group: 1, uid: 12\n",
      "group: 1, uid: 7\n",
      "group: 1, uid: 4\n",
      "group: 1, uid: 19\n",
      "3) #fit: 12, #unfit: 0, #buffer: 8\n"
     ]
    }
   ],
   "source": [
    "unfit_group_copy = {k:[i for i in v] for k, v in unfit_group.iteritems()}\n",
    "print unfit_group\n",
    "print \"*********************************\"   \n",
    "\n",
    "for g, uids in unfit_group_copy.iteritems():\n",
    "    for uid in uids:        \n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold, g)\n",
    "        \n",
    "        unfit_group[g].remove(uid)\n",
    "        if new_group is None:\n",
    "            buffer_group.append(uid)            \n",
    "        else:\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "tot_buffer_group = len(buffer_group)\n",
    "print \"3) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [11, 16, 2, 1, 19, 18], 1: [4, 3, 10, 13]}\n",
      "*********************************\n",
      "0) 0, 11\n",
      "1) 0, 16\n",
      "2) 0, 2\n",
      "3) 0, 1\n",
      "4) 0, 19\n",
      "5) 0, 18\n",
      "0) 1, 4\n",
      "1) 1, 3\n",
      "2) 1, 10\n",
      "3) 1, 13\n"
     ]
    }
   ],
   "source": [
    "unfit_group_copy = unfit_group.copy()\n",
    "print unfit_group\n",
    "print \"*********************************\"   \n",
    "\n",
    "for g, uids in unfit_group_copy.iteritems():\n",
    "    for i, uid in enumerate(uids):        \n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold, g)\n",
    "        print \"%d) %d, %d\" % (i, g, uid)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "13\n",
      "16\n",
      "7\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for g, uids in unfit_group_copy.iteritems():\n",
    "     for uid in uids:    \n",
    "            print uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
