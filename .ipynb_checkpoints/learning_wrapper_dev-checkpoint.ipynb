{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Structure\n",
    "* k: # of groups, or # of containers\n",
    "* one buffer\n",
    "* a member in buffer will be examined against all of newly learned distrance, all quantified distance metrics will be ranked by p-value in descending order. The top distance metrics is the one chosen for the user.\n",
    "* member of a container will be examined for the distance metrics learned for the population. If the member is not cosider enjoy a good fit of the distance metrics, the member will be checked with other alternative distance metris. Until at least one of qualified distance metrics found, the member is sent to the buffer.\n",
    "* overall fit is measured by the following metrics\n",
    "$$\n",
    "fs_1 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} / |U_{j}|) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "$$\n",
    "fs_2 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} / |U_{j}|^2) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "$$\n",
    "fs_3 = \\sum_{j = 1}^{k} (\\sum_{i \\in U_{j}} \\text{P-value}(u_i,D_j)_{i} \\cdot \\frac{N}{|U_{j}|^2}) + C \\cdot |\\text{buffer}|\n",
    "$$\n",
    "\n",
    "* $u_i$: $i$th user\n",
    "* $D_j$: the distance metrics learned for $j$th user group\n",
    "* $U_j$: $j$th user group\n",
    "* $|\\cdot|$: size of users in the container\n",
    "* $C$: the parameter determines the strength of penalty for more members in the buffer\n",
    "* $N$: the total number of users in fit group, $\\sum_{j = 1}^{k} |U_{j}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from GWDLearner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" wrap up the learning iteration\n",
    "\n",
    "functions:\n",
    "----------\n",
    "a. assigning member to fitted group\n",
    "b. test members against all distance metrics rather than its previous group's\n",
    "   [(group_index, pval)]\n",
    "c. sort all \n",
    "\n",
    "\n",
    "Parameters:\n",
    "-----------\n",
    "profile_df: {pandas.DataFrame}\n",
    "networkx: {networkx.Graph}\n",
    "k: {integer}, the target number of groups to learn\n",
    "min_delta_f: {float}, the minimal decrease in f score to continue learning\n",
    "\n",
    "Returns:\n",
    "--------\n",
    "\"\"\"\n",
    "def init_embed_list(n):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ls = []\n",
    "    for i in range(n):\n",
    "        ls.append([])\n",
    "    return ls\n",
    "\n",
    "def init_dict_list(k):\n",
    "    \"\"\" create dictionary with k items, each\n",
    "        item is a empty list\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for i in range(k):\n",
    "        res_dict[i] = []\n",
    "    return res_dict\n",
    "\n",
    "k = 2\n",
    "min_delta_f = 0.001\n",
    "\n",
    "dist_metrics = init_dict_list(k)\n",
    "fit_group = init_dict_list(k)\n",
    "unfit_group = init_dict_list(k)\n",
    "buffer_group = []\n",
    "fit_pvals = init_dict_list(k)\n",
    "unfit_pvals = init_dict_list(k)\n",
    "\n",
    "# results value\n",
    "fs_hist = []\n",
    "knowledge_pkg = []\n",
    "\n",
    "# *. distance has been learned\n",
    "# *. group composite is inherited from the previous iteration\n",
    "\n",
    "dist_metrics = {0: [0.1, 0.3, 0.6, 0], 1: [0.5, 0.1, 0.4, 0], 2: [0.25, 0.25, 0.25, 0.25]}\n",
    "fit_group = {0:[1, 2, 4, 5], 1:[3, 6, 7], 2:[8, 9]}\n",
    "fit_pvals = {0:[0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
    "buffer_group = [10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.192895674001\n",
      "0.891109151516\n",
      "0.538987111551\n",
      "0.719288232637\n",
      "0.244418785844\n",
      "0.666233350896\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ae62aa7eff24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpval\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfit_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0munfit_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# examine user aginst the group distance metrics\n",
    "# retain members bearing fit\n",
    "# reassign users to unfit_group\n",
    "for i, g in fit_group.iteritems():\n",
    "    for j, u in enumerate(g):\n",
    "        # print \"(%d, %d)\" % (i, u)\n",
    "        pval = np.random.uniform(0, 1, 1)[0]\n",
    "        print pval\n",
    "        if pval > 0.5:\n",
    "            fit_group[i].remove(u)\n",
    "            unfit_group[i].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5]\n",
      "[3, 6, 7]\n",
      "[8, 9]\n"
     ]
    }
   ],
   "source": [
    "for i, g in fit_group.iteritems():\n",
    "    print g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.1, 0.4, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.5, 0.1, 0.4, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.5, 0.1, 0.4, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.5, 0.1, 0.4, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.1, 0.3, 0.6, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.1, 0.3, 0.6, 0], [0.1, 0.1, 0.1, 0.7]]\n",
      "[[0.1, 0.3, 0.6, 0], [0.1, 0.1, 0.1, 0.7]]\n"
     ]
    }
   ],
   "source": [
    "# fit_group\n",
    "# unfit_group\n",
    "for i, g in enumerate(fit_group):\n",
    "    comp_dist = dist_metrics[:i] + dist_metrics[(i + 1):]\n",
    "    for j, u in enumerate(g):\n",
    "        print comp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_fit_group(uid, dist_metrics, threshold,  current_group = []):\n",
    "    \"\"\" calculate user p-value for the distance metrics of\n",
    "        each group\n",
    "        \n",
    "    Parameters:\n",
    "    ----------\n",
    "    uid: {integer}, user id\n",
    "    current_group: {integer}, group index\n",
    "    dist_metrics: {dictionary}, all {index: distance_metrics}\n",
    "    threshold: {float}, threshold for qualifying pvalue of ks-test\n",
    "    \n",
    "    Resutls:\n",
    "    --------\n",
    "    res: {list}, [group_idx, pvalue]\n",
    "    \"\"\"\n",
    "    if current_group == []:\n",
    "        other_group = dist_metrics.keys()\n",
    "        other_dist_metrics = dist_metrics.values()\n",
    "    else:\n",
    "        other_group = [i for i in dist_metrics.keys() if i != current_group]\n",
    "        other_dist_metrics = [d for g, d in dist_metrics.iteritems() if g != current_group]\n",
    "    \n",
    "    pvals = []\n",
    "\n",
    "    for d in other_dist_metrics:\n",
    "        # loop through all distance metrics and calculate\n",
    "        # p-value of ks-test by applying it to the user\n",
    "        # relationships\n",
    "        # sdist, ddist = user_grouped_dist(user_id = uid, weights=dist_metrics, *profile_df{DataFramw, ID}*,\n",
    "        #                   *friends_networkx*)\n",
    "        # pval = user_dist_kstest(sim_dist_vec=sdist, diff_dist_vec=ddist, fit_rayleigh=True, _n=1000)\n",
    "        pval = np.random.uniform(0, 1, 1)\n",
    "        pvals.append(pval)\n",
    "        \n",
    "    min_pval = min(pvals)[0]\n",
    "    min_index = [i for i, p in enumerate(pvals) if p == min_pval][0]\n",
    "    best_group = other_group[min_index]\n",
    "    \n",
    "    if min_pval >= threshold:\n",
    "        # if min_pval >= threshold, user is not considered \n",
    "        # to have a good fit by any of distance metrics\n",
    "        best_group = np.nan\n",
    "        min_pval = np.nan\n",
    "    \n",
    "    return (best_group, min_pval)\n",
    "\n",
    "def get_fit_score(fit_pvals, buffer_group, c, t=2):\n",
    "    \"\"\" calculate the fit score given the member composite\n",
    "        and its pvalues with its group distance metrics, with\n",
    "        c determinng the strength of penalty for keeping a \n",
    "        larger number of users in buffer_group\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit_pvals: {dict}, {index: [pvalues]}\n",
    "    buffer_group: {list}, [userid, ...]\n",
    "    c: {float}, \n",
    "    t: {integer} 1, 2 or 3\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fit_score: {float}, fit score, a smaller value indidcate\n",
    "                a overall better fit\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    fit_group = fit_group\n",
    "    fit_pvals = fit_pvals\n",
    "    buffer_group = buffer_group\n",
    "    c = 0.1\n",
    "    fscore = get_fit_score(fit_group, fit_pvals, buffer_group, c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted sum of pvalues \n",
    "    if t not in [1, 2, 3]:\n",
    "        raise NameError('Error: type (t) is not legal value (1 or 2)!')\n",
    "    \n",
    "    wsum_pval = 0\n",
    "    if t == 1:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v) * 1.0 / len(v))\n",
    "    if t == 2:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "    if t == 3:\n",
    "        num_users = 0\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "            num_users += len(v)\n",
    "        wsum_pval = num_users * 1.0 * wsum_pval\n",
    "\n",
    "    penalty = c * len(buffer_group)\n",
    "    fit_score = wsum_pval + penalty # smaller value indicates a better overall fit\n",
    "    \n",
    "    return fit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_metrics = {0: [0.1, 0.3, 0.6, 0], 1: [0.5, 0.1, 0.4, 0], 2: [0.25, 0.25, 0.25, 0.25]}\n",
    "fit_group = {0:[1, 2, 4, 5], 1:[3, 6, 7], 2:[8, 9]}\n",
    "unfit_group = {}\n",
    "fit_pvals = {0:[0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
    "buffer_group = []\n",
    "\n",
    "threshold = 0.5\n",
    "c = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 01: learn distance metrics\n",
    "for g, uids in fit_group.iteritems():\n",
    "    # function learn\n",
    "    dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "    dist_metrics[g] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.088655901698830308, 0.2259672307541073, 0.036497357427248578, 0.36885043025878117], 1: [0.76391743027718451, 0.011670212567600591, 0.85608215240779029, 0.310455275695802], 2: [0.77879957146338263, 0.3269606537780031, 0.31095039311610195, 0.32162244322658917]}\n",
      "fit_group: {0: [1, 2, 4, 5], 1: [3, 6, 7], 2: [8, 9]}\n",
      "fit_pvals: {0: [0.2, 0.12, 0.04, 0.21], 1: [0.31, 0.22, 0.17], 2: [0.02, 0.05]}\n",
      "unfit_group: {}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 02: update the member composite with updated group distance metrics\n",
    "# threshold is needed to be defined\n",
    "fit_group_copy = fit_group.copy()\n",
    "for g, uids in fit_group_copy.iteritems():\n",
    "    target_dist = dist_metrics[g]\n",
    "    for uid in uids:\n",
    "        # calcualte the ks-pvalue with update distance metrics\n",
    "        # target_dist\n",
    "        pval = np.random.uniform(0, 1, 1)[0]\n",
    "        if pval >= threshold:\n",
    "            # remove the user and its information \n",
    "            # from relevant container\n",
    "            idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "            fit_group[g].pop(idx)\n",
    "            fit_pvals[g].pop(idx)\n",
    "            # add the user to the unfit_group\n",
    "            if g in unfit_group:\n",
    "                unfit_group[g].append(uid)\n",
    "            else:\n",
    "                unfit_group[g] = [uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.088655901698830308, 0.2259672307541073, 0.036497357427248578, 0.36885043025878117], 1: [0.76391743027718451, 0.011670212567600591, 0.85608215240779029, 0.310455275695802], 2: [0.77879957146338263, 0.3269606537780031, 0.31095039311610195, 0.32162244322658917]}\n",
      "fit_group: {0: [2, 4], 1: [6, 7], 2: [8, 9]}\n",
      "fit_pvals: {0: [0.12, 0.04], 1: [0.22, 0.17], 2: [0.02, 0.05]}\n",
      "unfit_group: {0: [1, 5], 1: [3]}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 03: test members in unfit_group to see\n",
    "# if it has a good fit with other distmetrics\n",
    "# make a copy of the buffer group container\n",
    "buffer_group_copy = [i for i in buffer_group]\n",
    "if len(buffer_group_copy) > 0:\n",
    "    for uid in buffer_group_copy:\n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold)\n",
    "        if not np.isnan(new_pval):\n",
    "            buffer_group.remove(uid)\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]\n",
    "                \n",
    "\n",
    "unfit_group_copy = unfit_group.copy()\n",
    "\n",
    "for g, uids in unfit_group_copy.iteritems():\n",
    "    for uid in uids:        \n",
    "        new_group, new_pval = find_fit_group(uid, dist_metrics, threshold, g)\n",
    "        if np.isnan(new_pval):\n",
    "            buffer_group.append(uid)\n",
    "        else:\n",
    "            unfit_group[g].remove(uid)\n",
    "            if new_group in fit_group:\n",
    "                fit_group[new_group].append(uid)\n",
    "                fit_pvals[new_group].append(new_pval)\n",
    "            else:\n",
    "                fit_group[new_group] = [uid]\n",
    "                fit_pvals[new_group] = [new_pval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_metrics: {0: [0.088655901698830308, 0.2259672307541073, 0.036497357427248578, 0.36885043025878117], 1: [0.76391743027718451, 0.011670212567600591, 0.85608215240779029, 0.310455275695802], 2: [0.77879957146338263, 0.3269606537780031, 0.31095039311610195, 0.32162244322658917]}\n",
      "fit_group: {0: [2, 4, 3], 1: [6, 7, 1], 2: [8, 9]}\n",
      "fit_pvals: {0: [0.12, 0.04, 0.46019120599190588], 1: [0.22, 0.17, 0.21619468440433143], 2: [0.02, 0.05]}\n",
      "unfit_group: {0: [5], 1: []}\n",
      "buffer_group: []\n"
     ]
    }
   ],
   "source": [
    "#unfit_group[g]\n",
    "print \"dist_metrics:\",dist_metrics\n",
    "print \"fit_group:\", fit_group \n",
    "print \"fit_pvals:\", fit_pvals\n",
    "print \"unfit_group:\", unfit_group\n",
    "print \"buffer_group:\", buffer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443795296799\n",
      "0.153765098933\n",
      "1.23012079146\n"
     ]
    }
   ],
   "source": [
    "# step 04: calculate current fscore\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=1)\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=2)\n",
    "print get_fit_score(fit_pvals, buffer_group, c, t=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.467770337717\n"
     ]
    }
   ],
   "source": [
    "package = {\"dist_metrics\": dist_metrics, \n",
    "           \"fit_group\": fit_group, \n",
    "           \"buffer_group\": buffer_group}\n",
    "\n",
    "#fs_hist = []\n",
    "#knowledge_pkg = []\n",
    "fs_hist.append(fs)\n",
    "knowledge_pkg.append(package)\n",
    "best_fs = min(fs_hist)\n",
    "\n",
    "if best_fs - fs <= min_delta_f:\n",
    "    # _no_imp_counter defined prior to while()\n",
    "    # while(_no_imp_counter < max_iter):\n",
    "    _no_imp_counter += _no_imp_counter \n",
    "else:\n",
    "    _no_imp_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop the iteractive learning framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input info.:\n",
    "----------\n",
    "profile_df\n",
    "friend_networkx\n",
    "\n",
    "control parameters:\n",
    "-------------------\n",
    "t: fit score type\n",
    "\n",
    "tuning parameter:\n",
    "-----------------\n",
    "c: regularization strength\n",
    "min_delta_f: threshold for significant improvement\n",
    "max_iter: maxmium number of trivial trial learning in a row \n",
    "\"\"\"\n",
    "\n",
    "# initiate the containers:\n",
    "dist_metrics = init_dict_list(k) # distance metrics containers\n",
    "fit_group = init_dict_list(k)    # members composition in fit groups\n",
    "fit_pvals = init_dict_list(k)    # members' pvalue of KStest with their group distance metrics\n",
    "unfit_group = init_dict_list(k)  # members is not considerd fit by its group distance metrics\n",
    "unfit_pvals = init_dict_list(k)  # pvalues for members in unfit_group (maybe can be deleted)\n",
    "buffer_group = []                # members are not considered having fit\n",
    "\n",
    "# results value\n",
    "fs_hist = []       # list of fit scores in sequence (lastest one is the last)\n",
    "knowledge_pkg = [] # {index: {\"dist_metrics\", \"fit_group\", \"buffer_group\"}} \n",
    "\n",
    "# calculate the the init distance metrics\n",
    "# samping is subset of users to calculate\n",
    "# the distance metrics is good method\n",
    "\n",
    "# dist_metrics: ldm() with subset of users\n",
    "# fit_group: subsets of users\n",
    "# buffer_group: useres are not sampled \n",
    "\n",
    "_no_imp_counter = 0\n",
    "\n",
    "while _no_imp_counter < max_iter:\n",
    "    \n",
    "    # step 01: learn distance metrics\n",
    "    for g, uids in fit_group.iteritems():\n",
    "        # learn distance metrics\n",
    "        # here to update the computational mechanism\n",
    "        dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "        dist_metrics[g] = dist\n",
    "        \n",
    "    # step 02: update the member composite with updated group distance metrics\n",
    "    # threshold is needed to be defined\n",
    "    fit_group_copy = fit_group.copy()\n",
    "    for g, uids in fit_group_copy.iteritems():\n",
    "        target_dist = dist_metrics[g]\n",
    "        for uid in uids:\n",
    "            # calcualte the ks-pvalue with update distance metrics\n",
    "            # target_dist\n",
    "            pval = np.random.uniform(0, 1, 1)[0]\n",
    "            if pval >= threshold:\n",
    "                # remove the user and its information \n",
    "                # from relevant container\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_group[g].pop(idx)\n",
    "                fit_pvals[g].pop(idx)\n",
    "                # add the user to the unfit_group\n",
    "                if g in unfit_group:\n",
    "                    unfit_group[g].append(uid)\n",
    "                else:\n",
    "                    unfit_group[g] = [uid]\n",
    "                    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
