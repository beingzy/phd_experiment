{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "from networkx import Graph\n",
    "\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Develop a kstest for two samples \n",
    "## with one-sided hypothesis\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.numpy2ri import numpy2ri\n",
    "\n",
    "robjects.conversion.py2ri = numpy2ri\n",
    "rstats = importr(\"stats\")\n",
    "\n",
    "def kstest_2samp_greater(x, y):\n",
    "    \n",
    "    \"\"\" Calcualte the test statistics and Pvalue for\n",
    "        KS-test with two samples\n",
    "        \n",
    "        Hypothesis:\n",
    "        H0: distr.(x) >= distr.(y) # not less than\n",
    "        H1: distr.(x) < distr.(y)\n",
    "        \n",
    "        Pramaters:\n",
    "        ----------\n",
    "        x: {vector-like}\n",
    "        y: {vector-like}\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        cv, pval: {tuple}, test statistics, pvalue\n",
    "    \"\"\"\n",
    "    \n",
    "    greater = np.array([\"less\"], dtype=\"str\")\n",
    "    res = rstats.ks_test(x, y, alternative=greater)\n",
    "    ts, pval = res[0][0], res[1][0]\n",
    "    return ts, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "#from scipy.stats import ks_twosamp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "from networkx import Graph\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "\n",
    "def user_grouped_dist(user_id, weights, profile_df, friend_networkx):\n",
    "    \"\"\" Calculate distances between a user and whose friends\n",
    "        and distance between a user and whose non-friends.\n",
    "        The groupped distance vector will be output.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    * user_id: {integer}, the target user's ID\n",
    "    * weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    * friend_networkx: {networkx.Graph()}, Graph() object from Networkx\n",
    "        to store the relationships informat\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list, list of integers}, a list of two lists, which store the distances\n",
    "        of either friends and non-friends separately.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[ [\"ID\"] + cols ]\n",
    "    user_dist = user_grouped_dist(user_id = 0, weights = weights\n",
    "        , profile_df, friends_df)\n",
    "    print user_dist[\"friends\"]\n",
    "    print user_dist[\"nonfriends\"]\n",
    "    \"\"\"\n",
    "    cols = [col for col in profile_df.columns if col is not \"ID\"]\n",
    "    # get the user profile information of the target users\n",
    "    user_profile = profile_df.ix[profile_df.ID == user_id, cols].as_matrix()\n",
    "    # user_row = profile_df.ix[profile_df.ID == user_id, cols]\n",
    "    # user_profile = user_row.values.tolist()[0]\n",
    "    # get the user_id of friends of the target user\n",
    "    friends_ls = friend_networkx.neighbors(user_id)\n",
    "    all_ids = profile_df.ID\n",
    "    non_friends_ls = [u for u in all_ids if u not in friends_ls + [user_id]]\n",
    "\n",
    "    sim_dist_vec = []\n",
    "    for f_id in friends_ls:\n",
    "        friend_profile = profile_df.ix[profile_df.ID == f_id, cols].as_matrix()\n",
    "        # friend_row = profile_df.ix[profile_df.ID == f_id, cols]\n",
    "        # friend_profile = friend_row.values.tolist()[0]\n",
    "        the_dist = weighted_euclidean(user_profile, friend_profile, weights)\n",
    "        sim_dist_vec.append(the_dist)\n",
    "\n",
    "    diff_dist_vec = []\n",
    "    for nf_id in non_friends_ls:\n",
    "        nonfriend_profile = profile_df.ix[profile_df.ID == nf_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, nonfriend_profile, weights)\n",
    "        diff_dist_vec.append(the_dist)\n",
    "\n",
    "    res = [sim_dist_vec, diff_dist_vec]\n",
    "    return res\n",
    "\n",
    "\n",
    "def user_dist_kstest(sim_dist_vec, diff_dist_vec,\n",
    "                     fit_rayleigh=False, _n=100):\n",
    "\n",
    "    \"\"\" Test the goodness of a given weights to defferentiate friend distance\n",
    "        distributions and non-friend distance distributions of a given user.\n",
    "        The distance distribution can be assumed to follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sim_dist_vec: {vector-like (list), float}, distances between friends\n",
    "                  and the user\n",
    "    diff_dist_vec: {vector-like (list), float}, distances between non-fri\n",
    "                   -ends and the user\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    * res: {float}: p-value of ks-test with assumption that distances follow\n",
    "            Rayleigh distribution.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    pval = user_dist_kstest(sim_dist_vec, diff_dist_vec)\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert list to numpy.arrray, which can be\n",
    "    # automatice transfer to R readable objects\n",
    "    # for R-function, if the proper setting is\n",
    "    # configured\n",
    "    sim_dist_vec = np.array(sim_dist_vec)\n",
    "    diff_dist_vec = np.array(diff_dist_vec)\n",
    "    \n",
    "    if fit_rayleigh:\n",
    "        friend_param = rayleigh.fit(sim_dist_vec)\n",
    "        nonfriend_param = rayleigh.fit(diff_dist_vec)\n",
    "\n",
    "        samp_friend = rayleigh.rvs(friend_param[0], friend_param[1], _n)\n",
    "        samp_nonfriend = rayleigh.rvs(nonfriend_param[0], nonfriend_param[1], _n)\n",
    "\n",
    "        # ouput p-value of ks-test\n",
    "        res = kstest_2samp_greater(samp_friend, samp_nonfriend)[1]\n",
    "    else:\n",
    "        res = kstest_2samp_greater(sim_dist_vec, diff_dist_vec)[1]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def users_filter_by_weights(weights, profile_df, friends_networkx,\n",
    "                            pval_threshold=0.5,\n",
    "                            mutate_rate=0.4,\n",
    "                            min_friend_cnt=10,\n",
    "                            users_list=None,\n",
    "                            fit_rayleigh=False,\n",
    "                            _n=1000,\n",
    "                            is_debug=False):\n",
    "    \"\"\" Split users into two groups, \"keep\" and \"mutate\", with respect to\n",
    "        p-value of the ks-test on the null hypothesis that the distribution of\n",
    "        friends' weighted distance is not significantly different from the\n",
    "        couterpart for non-friends. Assume the weighted distances of each group\n",
    "        follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends_networkx: {networkx.Graph()}, Graph() object from Networkx to store\n",
    "        the relationships information\n",
    "    pval_threshold: {float}, the threshold for p-value to reject hypothesis\n",
    "    min_friend_cnt: {integer}, drop users whose total of friends is less than\n",
    "       this minimum count\n",
    "    mutate_rate: {float}, a float value [0 - 1] determine the percentage of\n",
    "       bad_fits member sent to mutation\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "    is_debug: {boolean}, to control if it yeilds by-product information\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list} grouped list of user ids\n",
    "        res[0] stores all users whose null hypothesis does not holds;\n",
    "        res[1] stores all users whose null hypothesis hold null hypothesis,\n",
    "        given weights, distance distribution of all friends is significantly\n",
    "        different from distance distribution of all non-friends\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[[\"ID\"] + cols]\n",
    "    grouped_users = users_filter_by_weights(weights,\n",
    "                       profile_df, friends_df, pval_threshold = 0.10,\n",
    "                       min_friend_cnt = 10)\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    min_friend_cnt is not implemented\n",
    "    \"\"\"\n",
    "    # all_users_ids = list(set(profile_df.ID))\n",
    "    # users_list\n",
    "    # container for users meeting different critiria\n",
    "    pvals = []\n",
    "    if users_list is None:\n",
    "        users_list = list(profile_df.ix[:, 0])\n",
    "\n",
    "    for uid in users_list:\n",
    "        res_dists = user_grouped_dist(uid, weights, profile_df, friends_networkx)\n",
    "        pval = user_dist_kstest(res_dists[0], res_dists[1], fit_rayleigh, _n)\n",
    "        pvals.append(pval)\n",
    "\n",
    "    sorted_id_pval = sorted(zip(users_list, pvals), key=lambda x: x[1])\n",
    "\n",
    "    if is_debug:\n",
    "        # users having KS-test pvalue < alpha, H0 is rejceted \n",
    "        good_fits = [i for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "        bad_fits = [i for i, p in sorted_id_pval if p < pval_threshold]\n",
    "        good_pvals = [p for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "        bad_pvals = [p for i, p in sorted_id_pval if p < pval_threshold]\n",
    "    else:\n",
    "        good_fits = [i for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "        bad_fits = [i for i, p in sorted_id_pval if p < pval_threshold]\n",
    "\n",
    "    if len(bad_fits) > 0:\n",
    "        mutate_size = np.ceil(len(bad_fits) * mutate_rate)\n",
    "        mutate_size = max(int(mutate_size), 1)\n",
    "        id_retain = good_fits + bad_fits[mutate_size:]\n",
    "        id_mutate = bad_fits[:mutate_size]\n",
    "        # split pval\n",
    "        if is_debug:\n",
    "            if len(good_pvals) > 0 or len(bad_pvals) > 0:\n",
    "                pval_retain = good_pvals + bad_pvals[mutate_size:]\n",
    "                pval_mutate = bad_pvals[mutate_size:]\n",
    "    else:\n",
    "        id_retain = good_fits\n",
    "        id_mutate = bad_fits\n",
    "\n",
    "        if is_debug:\n",
    "            if len(good_pvals) > 0 or len(bad_pvals) > 0:\n",
    "                pval_retain = pval_retain\n",
    "                pval_mutate = bad_pvals\n",
    "\n",
    "    if is_debug:\n",
    "        res = [id_retain, id_mutate, pval_retain, pval_mutate]\n",
    "    else:\n",
    "        res = [id_retain, id_mutate]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def ldm_train_with_list(users_list, profile_df, friends, retain_type=1):\n",
    "    \"\"\" learning distance matrics with ldm() instance, provided with selected\n",
    "        list of users.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends: {list of tuple}, each tuple keeps a pair of user id\n",
    "    retain_type: {integer}, 0, adopting 'or' logic by keeping relationship in\n",
    "        friends_df if either of entities is in user_list 1, adopting 'and'\n",
    "        logic\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {vector-like, float}, output of ldm.get_transform_matrix()\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    new_dist_metrics = ldm_train_with_list(user_list, profile_df, friends_df)\n",
    "    \"\"\"\n",
    "    if retain_type == 0:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list or b in users_list]\n",
    "    else:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list and b in users_list]\n",
    "    \n",
    "    ldm = LDM()    \n",
    "    ldm.fit(profile_df, friends)\n",
    "    weight_vec = ldm.get_transform_matrix()\n",
    "    return weight_vec     \n",
    "\n",
    "\n",
    "def init_embed_list(n):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ls = []\n",
    "    for i in range(n):\n",
    "        ls.append([])\n",
    "    return ls\n",
    "\n",
    "\n",
    "def init_dict_list(k):\n",
    "    \"\"\" create dictionary with k items, each\n",
    "        item is a empty list\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for i in range(k):\n",
    "        res_dict[i] = []\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def find_fit_group(uid, dist_metrics, profile_df,\n",
    "                   friend_networkx, threshold=0.5,\n",
    "                   current_group=None, fit_rayleigh=False):\n",
    "    \"\"\" calculate user p-value for the distance metrics of\n",
    "        each group\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    uid: {integer}, user id\n",
    "    dist_metrics: {dictionary}, all {index: distance_metrics}\n",
    "    profile_df: {DataFrame}, user profile includes \"ID\" column\n",
    "    friend_networkx: {networkx.Graph}, user relationships\n",
    "    threshold: {float}, threshold for qualifying pvalue of ks-test\n",
    "    current_group: {integer}, group index\n",
    "    fit_rayleigh: {boolean}\n",
    "\n",
    "    Resutls:\n",
    "    --------\n",
    "    res: {list}, [group_idx, pvalue]\n",
    "    \"\"\"\n",
    "    if current_group is None:\n",
    "        other_group = dist_metrics.keys()\n",
    "        other_dist_metrics = dist_metrics.values()\n",
    "    else:\n",
    "        other_group = [i for i in dist_metrics.keys() if i != current_group]\n",
    "        other_dist_metrics = [d for g, d in dist_metrics.iteritems() if g != current_group]\n",
    "\n",
    "    if len(other_dist_metrics) > 0:\n",
    "        # only excute this is at least one alternative group\n",
    "        pvals = []\n",
    "\n",
    "        for d in other_dist_metrics:\n",
    "            # loop through all distance metrics and calculate\n",
    "            # p-value of ks-test by applying it to the user\n",
    "            # relationships\n",
    "            sdist, ddist = user_grouped_dist(user_id=uid, weights=d,\n",
    "                        profile_df=profile_df, friend_networkx=friend_networkx)\n",
    "            pval = user_dist_kstest(sim_dist_vec=sdist, diff_dist_vec=ddist,\n",
    "                                fit_rayleigh=fit_rayleigh, _n=1000)\n",
    "            pvals.append(pval)\n",
    "\n",
    "        max_pval = max(pvals)\n",
    "        max_index = [i for i, p in enumerate(pvals) if p == max_pval][0]\n",
    "        best_group = other_group[max_index]\n",
    "\n",
    "        if max_pval < threshold:\n",
    "            # reject null hypothesis\n",
    "            best_group = None\n",
    "            max_pval = None\n",
    "\n",
    "    else:\n",
    "        best_group = None\n",
    "        max_pval = None\n",
    "\n",
    "    return (best_group, max_pval)\n",
    "\n",
    "def get_fit_score(fit_pvals, buffer_group, c):\n",
    "    \"\"\" calculate the fit score given the member composite\n",
    "        and its pvalues with its group distance metrics, with\n",
    "        c determinng the strength of penalty for keeping a \n",
    "        larger number of users in buffer_group\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit_pvals: {dict}, {index: [pvalues]}\n",
    "    buffer_group: {list}, [userid, ...]\n",
    "    c: {float}, \n",
    "    t: {integer} 1, 2 or 3, type of fit score\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fit_score: {float}, fit score, a smaller value indidcate\n",
    "                a overall better fit\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    fit_group = fit_group\n",
    "    fit_pvals = fit_pvals\n",
    "    buffer_group = buffer_group\n",
    "    c = 0.1\n",
    "    fscore = get_fit_score(fit_group, fit_pvals, buffer_group, c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted sum of pvalues \n",
    "    wsum_pval = 0\n",
    "    num_users = 0\n",
    "    for g, v in fit_pvals.iteritems():\n",
    "        wsum_pval += sum(np.array(v) * 1.0) * (len(v) * len(v)) \n",
    "        num_users += len(v)\n",
    "    wsum_pval = wsum_pval * 1.0 / num_users\n",
    "    \n",
    "    penalty = c * len(buffer_group)\n",
    "    fit_score = wsum_pval - penalty # smaller value indicates a better overall fit\n",
    "    \n",
    "    return fit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/sim_data_yi/\" \n",
    "\n",
    "users_df   = pd.read_csv(DATA_PATH + \"users_profile.csv\", header = 0, sep = \",\")\n",
    "friends_df = pd.read_csv(DATA_PATH + \"friendships.csv\", header = 0, sep = \",\")\n",
    "dist_df    = pd.read_csv(DATA_PATH + \"dist_mat.csv\", header = 0, sep = \",\")\n",
    "\n",
    "friends_df = friends_df[friends_df.isFriend == 1]\n",
    "friends_df[\"pair\"] = friends_df[[\"uid_a\", \"uid_b\"]].apply(lambda x: (int(x[0]), int(x[1])), axis=1)\n",
    "friends_df.drop(\"isFriend\", axis=1, inplace=True)\n",
    "friends_df = friends_df[[\"pair\", \"uid_a\", \"uid_b\"]]\n",
    "friends_df.head(3)\n",
    "\n",
    "cols = [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]\n",
    "\n",
    "## subset users data to retain profile only\n",
    "profile_df = users_df[[\"ID\"] + cols]\n",
    "all_user_ids = list(set(users_df.ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx import Graph\n",
    "from timeit import timeit\n",
    "\n",
    "fnx = Graph()\n",
    "fnx.add_edges_from(friends_df.pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input info.:\n",
    "----------\n",
    "profile_df\n",
    "friend_networkx\n",
    "\n",
    "control parameters:\n",
    "-------------------\n",
    "t: fit score type\n",
    "\n",
    "tuning parameter:\n",
    "-----------------\n",
    "threshold: cutoff value for kstest\n",
    "c: regularization strength\n",
    "min_delta_f: threshold for significant improvement\n",
    "max_iter: maxmium number of trivial trial learning in a row \n",
    "\"\"\"\n",
    "# input info\n",
    "k = 2 # user input\n",
    "\n",
    "# user_profile\n",
    "\n",
    "# final user interface\n",
    "# necessary\n",
    "# profile_df, \n",
    "# friends_ls\n",
    "# fnx\n",
    "\n",
    "profile_df = profile_df      # user profile\n",
    "friends_ls = friends_df.pair # user relationship \n",
    "friend_networkx = fnx        # user friendswork\n",
    "\n",
    "# tuing parameters\n",
    "t = 2               # type of Fit Score formula\n",
    "c = 0.1             # penalty for larger buffer group in Fit Score calculation\n",
    "threshold = 0.10    # ks-test threshold for fit or not fit\n",
    "n = 1000            # ks-test sample size for rayleigh \n",
    "min_size_group = 10 # minimal group size\n",
    "min_delta_f = 0.02  # minimal reduction for a significant fit improvement\n",
    "max_iter = 5       # max number of trivial iteration of learning\n",
    "is_fit_distr = False #\n",
    "\n",
    "# initiate the containers:\n",
    "dist_metrics = init_dict_list(k) # distance metrics containers\n",
    "fit_group = init_dict_list(k)    # members composition in fit groups\n",
    "fit_pvals = init_dict_list(k)    # members' pvalue of KStest with their group distance metrics\n",
    "unfit_group = init_dict_list(k)  # members is not considerd fit by its group distance metrics\n",
    "unfit_pvals = init_dict_list(k)  # pvalues for members in unfit_group (maybe can be deleted)\n",
    "buffer_group = []                # members are not considered having fit\n",
    "\n",
    "# results value\n",
    "fs_hist = []       # list of fit scores in sequence (lastest one is the last)\n",
    "knowledge_pkg = [] # {index: {\"dist_metrics\", \"fit_group\", \"buffer_group\"}} \n",
    "\n",
    "# calculate the the init distance metrics\n",
    "\n",
    "# sampling is subset of users to calculate\n",
    "# the distance metrics is good method\n",
    "\n",
    "# dist_metrics: ldm() with subset of users\n",
    "# fit_group: subsets of users\n",
    "# buffer_group: useres are not sampled \n",
    "\n",
    "# provide initial composition of fit_group\n",
    "# and buffer_group for iterative learning\n",
    "# procedure\n",
    "# the even sampling strategy is implemeted\n",
    "# here, however, \n",
    "all_uids = list(set(profile_df.ID))\n",
    "\n",
    "samp_size = len(all_uids) / k \n",
    "samp_sizes = [samp_size] * k\n",
    "all_uids_copy = [i for i in all_uids]\n",
    "# all_uids_copy = list(set(profile_df.ID))\n",
    "\n",
    "# generate k groups of sample user groups\n",
    "for g, samp_size in zip(range(k), samp_sizes):\n",
    "    # draw samples and assign them to fit_group\n",
    "    samples = choice(all_uids_copy, samp_size, replace=False)\n",
    "    fit_group[g] = list(samples)\n",
    "    # remove samples from population pool\n",
    "    for uid in samples:\n",
    "        all_uids_copy.remove(uid)\n",
    "\n",
    "# initiate fit user pvals\n",
    "for g, uids in fit_group.iteritems():\n",
    "    fit_pvals[g] = [0] * len(uids)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** iterative learning begins ************************************\n",
      "1 iteration is in processing ...\n",
      "--- 21.42 seconds ---\n",
      "--- 28.52 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: -0.0019 s\n",
      "2 iteration is in processing ...\n",
      "--- 28.88 seconds ---\n",
      "--- 23.31 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: -0.0001 s\n",
      "3 iteration is in processing ...\n",
      "--- 21.19 seconds ---\n",
      "--- 28.00 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: -0.0001 s\n",
      "4 iteration is in processing ...\n",
      "--- 27.97 seconds ---\n",
      "--- 22.34 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: 0.0000 s\n",
      "5 iteration is in processing ...\n",
      "--- 21.11 seconds ---\n",
      "--- 28.01 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: 0.0000 s\n",
      "6 iteration is in processing ...\n",
      "--- 27.64 seconds ---\n",
      "--- 22.17 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: 0.0003 s\n",
      "7 iteration is in processing ...\n",
      "--- 20.83 seconds ---\n",
      "--- 27.75 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: -0.0002 s\n",
      "8 iteration is in processing ...\n",
      "--- 27.81 seconds ---\n",
      "--- 22.52 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: 0.0002 s\n",
      "9 iteration is in processing ...\n",
      "--- 20.98 seconds ---\n",
      "--- 28.29 seconds ---\n",
      "1) #fit: 11, #unfit: 89, #buffer: 0\n",
      "2) #fit: 11, #unfit: 89, #buffer: 0\n",
      "3) #fit: 100, #unfit: 0, #buffer: 0\n",
      "time elapsed: 0.0001 s\n",
      "10 iteration is in processing ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d550f5c02ec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmin_size_group\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldm_train_with_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfriends_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mdist_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-52fdda617fb1>\u001b[0m in \u001b[0;36mldm_train_with_list\u001b[1;34m(users_list, profile_df, friends, retain_type)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0mldm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[0mldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfriends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[0mweight_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweight_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, S, D)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0m_ratio\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, S, D)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mfitted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m--> 427\u001b[1;33m                                 callback=callback, **options)\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[1;31m# minimization routine wants f and g at the current x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36mobjective_func\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mobjective_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msquared_sum_grouped_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_grouped_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36msum_grouped_dist\u001b[1;34m(pair_list, data, weights)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0msum_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_grouped_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_pairwise_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpair_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36mall_pairwise_dist\u001b[1;34m(pair_list, data, weights)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpair_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairwise_dist_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36mpairwise_dist_wrapper\u001b[1;34m(pair, data, weights)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mweighted_euclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36mweighted_euclidean\u001b[1;34m(x, y, w)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# performance measurements\n",
    "durations = []\n",
    "\n",
    "_no_imp_counter = 0\n",
    "_loop_counter = 0\n",
    "\n",
    "print \"******************** iterative learning begins ************************************\"\n",
    "\n",
    "while _no_imp_counter < max_iter:\n",
    "    \n",
    "    _loop_counter += 1\n",
    "    print \"%d iteration is in processing ...\" % _loop_counter\n",
    "    start_time = timeit()\n",
    "    \n",
    "    # step 01: learn distance metrics\n",
    "    for g, uids in fit_group.iteritems():\n",
    "        # learn distance metrics\n",
    "        # here to update the computational mechanism\n",
    "        # dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "        if len(uids) >= min_size_group:\n",
    "            dist = ldm_train_with_list(uids, profile_df, friends_ls)\n",
    "            dist_metrics[g] = dist\n",
    "        else:\n",
    "            num_feat = profile_df.shape[1] - 1\n",
    "            dist_metrics[g] = [1] * num_feat\n",
    "        \n",
    "    # step 02: update the member composite with updated group \n",
    "    # distance metrics threshold is needed to be defined\n",
    "    fit_group_copy = {k:[i for i in v] for k, v in fit_group.iteritems()}\n",
    "    for g, uids in fit_group_copy.iteritems():\n",
    "        target_dist = dist_metrics[g]\n",
    "        for uid in uids:\n",
    "            sdist, ddist = user_grouped_dist(uid, target_dist, profile_df, \n",
    "                                         friend_networkx)\n",
    "            pval = user_dist_kstest(sdist, ddist, fit_rayleigh=is_fit_distr, _n=n)\n",
    "             \n",
    "            if pval >= threshold:\n",
    "                # remove the user and its information \n",
    "                # from relevant container\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_group[g].pop(idx)\n",
    "                # fit_group[g].remove(uid)\n",
    "                fit_pvals[g].pop(idx)\n",
    "                \n",
    "                # add the user to the unfit_group\n",
    "                if g in unfit_group:\n",
    "                    unfit_group[g].append(uid)\n",
    "                else:\n",
    "                    unfit_group[g] = [uid]\n",
    "            \n",
    "            else:\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_pvals[g][idx] = pval\n",
    "                \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"1) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    # step 03: test members in unfit_group to see\n",
    "    # if it has a good fit with other distmetrics\n",
    "    # make a copy of the buffer group container\n",
    "    buffer_group_copy = [i for i in buffer_group]\n",
    "    if len(buffer_group_copy) > 0:\n",
    "        for uid in buffer_group_copy:\n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, \n",
    "                                                 profile_df, friend_networkx, threshold,\n",
    "                                                fit_rayleigh=is_fit_distr)\n",
    "            if new_group is not None:\n",
    "                buffer_group.remove(uid)\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"2) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    unfit_group_copy = {k:[i for i in v] for k, v in unfit_group.iteritems()}\n",
    "    for g, uids in unfit_group_copy.iteritems():\n",
    "        for uid in uids:        \n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, profile_df, \n",
    "                                                 friend_networkx, threshold, g, \n",
    "                                                 fit_rayleigh=is_fit_distr)\n",
    "            unfit_group[g].remove(uid)\n",
    "\n",
    "            if new_pval is None:\n",
    "                buffer_group.append(uid)\n",
    "            else:\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"3) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                        \n",
    "    # step 04: calculate fit score\n",
    "    fs = get_fit_score(fit_pvals, buffer_group, c=c)\n",
    "    fs_hist.append(fs)\n",
    "    \n",
    "    # step 05: evaluate stop criteria\n",
    "    package = {\"dist_metrics\": dist_metrics, \n",
    "               \"fit_group\": fit_group, \n",
    "               \"buffer_group\": buffer_group}\n",
    "\n",
    "    knowledge_pkg.append(package)\n",
    "    best_fs = min(fs_hist)\n",
    "\n",
    "    if best_fs - fs <= min_delta_f:\n",
    "        _no_imp_counter += _no_imp_counter \n",
    "    else:\n",
    "        _no_imp_counter = 0\n",
    "        if threshold > 0.05:\n",
    "            threshold -= 0.01\n",
    "        elif threshold > 0.005:\n",
    "            threshold -= 0.001\n",
    "        \n",
    "    # print \"fit score (type-%d): %.3f\" % (t, fs)\n",
    "    # print \"best fit score: %.3f\" % best_fs\n",
    "    end_time = timeit()\n",
    "    duration = end_time - start_time\n",
    "    durations.append(duration)\n",
    "    print \"time elapsed: %.4f s\" % duration\n",
    "     \n",
    "print \"******************** ends ************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawDropouts(users, pvals, dropout=0.1, desc=False):\n",
    "    \"\"\" select a defined number of users from users\n",
    "        list, based on dropout rate.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    * users, list\n",
    "    * pvals, list\n",
    "    * dropout, float, dropout rate\n",
    "    * desc, boolean, True for sorting in descending order\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: tuple, (users, pvals, user_dropout)\n",
    "    \"\"\"\n",
    "\n",
    "    users_copy = [i for i in users]\n",
    "    pvals_copy = [i for i in pvals]\n",
    "    sort_idx = sorted(range(len(users_copy)), key=lambda k:pvals_copy[k],\n",
    "                      reverse=desc)\n",
    "    # calculate number of users for dropout\n",
    "    ndropout = int(np.ceil(len(users_copy) * dropout))\n",
    "\n",
    "    if len(users_copy) > ndropout:\n",
    "        if len(users_copy) >= 2:\n",
    "            user_dropout = []\n",
    "            pval_dropout = []\n",
    "            remove_idx = sort_idx[:ndropout]\n",
    "            for ridx in remove_idx:\n",
    "                u = users_copy.pop(ridx)\n",
    "                p = pvals_copy.pop(ridx)\n",
    "                user_dropout.append(u)\n",
    "                pval_dropout.append(p)\n",
    "\n",
    "    return (users, pvals, user_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error pop up for dropouting! \n",
      "\n",
      "error pop up for dropouting! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "dropouts = {}\n",
    "for g, uids in fit_group.iteritems():\n",
    "    try:\n",
    "        pvals = fit_pvals[g]\n",
    "        new_uids, new_pvals, dropout_users, dropout_pvals = drawDropouts(uids,\n",
    "            pvals, dropout, desc=False)\n",
    "        fit_group[g] = list(new_uids)\n",
    "        fit_pvals[g] = list(new_pvals)\n",
    "        dropouts[g]  = dropout_users\n",
    "    except:\n",
    "        print 'error pop up for dropouting! \\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-befee81046ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdrawDropouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-586d9d5f4689>\u001b[0m in \u001b[0;36mdrawDropouts\u001b[1;34m(users, pvals, dropout, desc)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mremove_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msort_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mndropout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mridx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mremove_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musers_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpvals_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0muser_dropout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop index out of range"
     ]
    }
   ],
   "source": [
    "drawDropouts(uids, pvals, dropout, desc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_copy = [i for i in uids]\n",
    "pvals_copy = [i for i in pvals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sort_idx = sorted(range(len(users_copy)), key=lambda k:pvals_copy[k],\n",
    "                      reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndropout = int(np.ceil(len(users_copy) * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
