{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "from networkx import Graph\n",
    "\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "from networkx import Graph\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "\n",
    "def user_grouped_dist(user_id, weights, profile_df, friend_networkx):\n",
    "    \"\"\" Calculate distances between a user and whose friends\n",
    "        and distance between a user and whose non-friends.\n",
    "        The groupped distance vector will be output.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    * user_id: {integer}, the target user's ID\n",
    "    * weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    * friend_networkx: {networkx.Graph()}, Graph() object from Networkx\n",
    "        to store the relationships informat\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list, list of integers}, a list of two lists, which store the distances\n",
    "        of either friends and non-friends separately.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[ [\"ID\"] + cols ]\n",
    "    user_dist = user_grouped_dist(user_id = 0, weights = weights\n",
    "        , profile_df, friends_df)\n",
    "    print user_dist[\"friends\"]\n",
    "    print user_dist[\"nonfriends\"]\n",
    "    \"\"\"\n",
    "    cols = [col for col in profile_df.columns if col is not \"ID\"]\n",
    "    # get the user profile information of the target users\n",
    "    # user_profile = profile_df.ix[profile_df.ID == user_id, cols].as_matrix()\n",
    "    user_row = profile_df.ix[profile_df.ID == user_id, cols]\n",
    "    user_profile = user_row.values.tolist()[0]\n",
    "    # get the user_id of friends of the target user\n",
    "    friends_ls = friend_networkx.neighbors(user_id)\n",
    "    all_ids = profile_df.ID\n",
    "    non_friends_ls = [u for u in all_ids if u not in friends_ls + [user_id]]\n",
    "\n",
    "    sim_dist_vec = []\n",
    "    for f_id in friends_ls:\n",
    "        # friend_profile = profile_df.ix[profile_df.ID == f_id, cols].as_matrix()\n",
    "        friend_row = profile_df.ix[profile_df.ID == f_id, cols]\n",
    "        friend_profile = friend_row.values.tolist()[0]\n",
    "        the_dist = weighted_euclidean(user_profile, friend_profile, weights)\n",
    "        sim_dist_vec.append(the_dist)\n",
    "\n",
    "    diff_dist_vec = []\n",
    "    for nf_id in non_friends_ls:\n",
    "        nonfriend_profile = profile_df.ix[profile_df.ID == nf_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, nonfriend_profile, weights)\n",
    "        diff_dist_vec.append(the_dist)\n",
    "\n",
    "    res = [sim_dist_vec, diff_dist_vec]\n",
    "    return res\n",
    "\n",
    "\n",
    "def user_dist_kstest(sim_dist_vec, diff_dist_vec,\n",
    "                     fit_rayleigh=False, _n=100):\n",
    "\n",
    "    \"\"\" Test the goodness of a given weights to defferentiate friend distance\n",
    "        distributions and non-friend distance distributions of a given user.\n",
    "        The distance distribution is considered to follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sim_dist_vec: {vector-like (list), float}, distances between friends\n",
    "                  and the user\n",
    "    diff_dist_vec: {vector-like (list), float}, distances between non-fri\n",
    "                   -ends and the user\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    * res: {float}: p-value of ks-test with assumption that distances follow\n",
    "            Rayleigh distribution.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    pval = user_dist_kstest(sim_dist_vec, diff_dist_vec)\n",
    "    \"\"\"\n",
    "    # is_valid = (len(sim_dist_vec) >= min_nobs) & \\\n",
    "    #           (len(diff_dist_vec) >= min_nobs) # not used yet\n",
    "    if fit_rayleigh:\n",
    "        friend_param = rayleigh.fit(sim_dist_vec)\n",
    "        nonfriend_param = rayleigh.fit(diff_dist_vec)\n",
    "\n",
    "        samp_friend = rayleigh.rvs(friend_param[0], friend_param[1], _n)\n",
    "        samp_nonfriend = rayleigh.rvs(nonfriend_param[0], nonfriend_param[1], _n)\n",
    "\n",
    "        # ouput p-value of ks-test\n",
    "        res = ks_2samp(samp_friend, samp_nonfriend)[1]\n",
    "    else:\n",
    "        res = ks_2samp(sim_dist_vec, diff_dist_vec)[1]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def users_filter_by_weights(weights, profile_df, friends_networkx,\n",
    "                            pval_threshold=0.5,\n",
    "                            mutate_rate=0.4,\n",
    "                            min_friend_cnt=10,\n",
    "                            users_list=None,\n",
    "                            fit_rayleigh=False,\n",
    "                            _n=1000,\n",
    "                            is_debug=False):\n",
    "    \"\"\" Split users into two groups, \"keep\" and \"mutate\", with respect to\n",
    "        p-value of the ks-test on the null hypothesis that the distribution of\n",
    "        friends' weighted distance is not significantly different from the\n",
    "        couterpart for non-friends. Assume the weighted distances of each group\n",
    "        follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends_networkx: {networkx.Graph()}, Graph() object from Networkx to store\n",
    "        the relationships information\n",
    "    pval_threshold: {float}, the threshold for p-value to reject hypothesis\n",
    "    min_friend_cnt: {integer}, drop users whose total of friends is less than\n",
    "       this minimum count\n",
    "    mutate_rate: {float}, a float value [0 - 1] determine the percentage of\n",
    "       bad_fits member sent to mutation\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "    is_debug: {boolean}, to control if it yeilds by-product information\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list} grouped list of user ids\n",
    "        res[0] stores all users whose null hypothesis does not holds;\n",
    "        res[1] stores all users whose null hypothesis hold null hypothesis,\n",
    "        given weights, distance distribution of all friends is significantly\n",
    "        different from distance distribution of all non-friends\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[[\"ID\"] + cols]\n",
    "    grouped_users = users_filter_by_weights(weights,\n",
    "                       profile_df, friends_df, pval_threshold = 0.10,\n",
    "                       min_friend_cnt = 10)\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    min_friend_cnt is not implemented\n",
    "    \"\"\"\n",
    "    # all_users_ids = list(set(profile_df.ID))\n",
    "    # users_list\n",
    "    # container for users meeting different critiria\n",
    "    pvals = []\n",
    "    if users_list is None:\n",
    "        users_list = list(profile_df.ix[:, 0])\n",
    "\n",
    "    for uid in users_list:\n",
    "        res_dists = user_grouped_dist(uid, weights, profile_df, friends_networkx)\n",
    "        pval = user_dist_kstest(res_dists[0], res_dists[1], fit_rayleigh, _n)\n",
    "        pvals.append(pval)\n",
    "\n",
    "    sorted_id_pval = sorted(zip(users_list, pvals), key=lambda x: x[1])\n",
    "\n",
    "    if is_debug:\n",
    "        good_fits = [i for i, p in sorted_id_pval if p < pval_threshold]\n",
    "        bad_fits = [i for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "        good_pvals = [p for i, p in sorted_id_pval if p < pval_threshold]\n",
    "        bad_pvals = [p for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "    else:\n",
    "        good_fits = [i for i, p in sorted_id_pval if p < pval_threshold]\n",
    "        bad_fits = [i for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "\n",
    "    if len(bad_fits) > 0:\n",
    "        mutate_size = np.ceil(len(bad_fits) * mutate_rate)\n",
    "        mutate_size = max(int(mutate_size), 1)\n",
    "        id_retain = good_fits + bad_fits[mutate_size:]\n",
    "        id_mutate = bad_fits[:mutate_size]\n",
    "        # split pval\n",
    "        if is_debug:\n",
    "            if len(good_pvals) > 0 or len(bad_pvals) > 0:\n",
    "                pval_retain = good_pvals + bad_pvals[mutate_size:]\n",
    "                pval_mutate = bad_pvals[mutate_size:]\n",
    "    else:\n",
    "        id_retain = good_fits\n",
    "        id_mutate = bad_fits\n",
    "\n",
    "        if is_debug:\n",
    "            if len(good_pvals) > 0 or len(bad_pvals) > 0:\n",
    "                pval_retain = pval_retain\n",
    "                pval_mutate = bad_pvals\n",
    "\n",
    "    if is_debug:\n",
    "        res = [id_retain, id_mutate, pval_retain, pval_mutate]\n",
    "    else:\n",
    "        res = [id_retain, id_mutate]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def ldm_train_with_list(users_list, profile_df, friends, retain_type=1):\n",
    "    \"\"\" learning distance matrics with ldm() instance, provided with selected\n",
    "        list of users.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends: {list of tuple}, each tuple keeps a pair of user id\n",
    "    retain_type: {integer}, 0, adopting 'or' logic by keeping relationship in\n",
    "        friends_df if either of entities is in user_list 1, adopting 'and'\n",
    "        logic\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {vector-like, float}, output of ldm.get_transform_matrix()\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    new_dist_metrics = ldm_train_with_list(user_list, profile_df, friends_df)\n",
    "    \"\"\"\n",
    "    if retain_type == 0:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list or b in users_list]\n",
    "    else:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list and b in users_list]\n",
    "    \n",
    "    ldm = LDM()    \n",
    "    ldm.fit(profile_df, friends)\n",
    "    weight_vec = ldm.get_transform_matrix()\n",
    "    return weight_vec     \n",
    "\n",
    "\n",
    "def init_embed_list(n):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ls = []\n",
    "    for i in range(n):\n",
    "        ls.append([])\n",
    "    return ls\n",
    "\n",
    "\n",
    "def init_dict_list(k):\n",
    "    \"\"\" create dictionary with k items, each\n",
    "        item is a empty list\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for i in range(k):\n",
    "        res_dict[i] = []\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def find_fit_group(uid, dist_metrics, profile_df,\n",
    "                   friend_networkx, threshold=0.5,  current_group = None):\n",
    "    \"\"\" calculate user p-value for the distance metrics of\n",
    "        each group\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    uid: {integer}, user id\n",
    "    dist_metrics: {dictionary}, all {index: distance_metrics}\n",
    "    profile_df: {DataFrame}, user profile includes \"ID\" column\n",
    "    friend_networkx: {networkx.Graph}, user relationships\n",
    "    threshold: {float}, threshold for qualifying pvalue of ks-test\n",
    "    current_group: {integer}, group index\n",
    "\n",
    "    Resutls:\n",
    "    --------\n",
    "    res: {list}, [group_idx, pvalue]\n",
    "    \"\"\"\n",
    "    if current_group is None:\n",
    "        other_group = dist_metrics.keys()\n",
    "        other_dist_metrics = dist_metrics.values()\n",
    "    else:\n",
    "        other_group = [i for i in dist_metrics.keys() if i != current_group]\n",
    "        other_dist_metrics = [d for g, d in dist_metrics.iteritems() if g != current_group]\n",
    "\n",
    "    if len(other_dist_metrics) > 0:\n",
    "        # only excute this is at least one alternative group\n",
    "        pvals = []\n",
    "\n",
    "        for d in other_dist_metrics:\n",
    "            # loop through all distance metrics and calculate\n",
    "            # p-value of ks-test by applying it to the user\n",
    "            # relationships\n",
    "            sdist, ddist = user_grouped_dist(user_id=uid, weights=d,\n",
    "                        profile_df=profile_df, friend_networkx=friend_networkx)\n",
    "            pval = user_dist_kstest(sim_dist_vec=sdist, diff_dist_vec=ddist,\n",
    "                                fit_rayleigh=True, _n=1000)\n",
    "            pvals.append(pval)\n",
    "\n",
    "        min_pval = min(pvals)[0]\n",
    "        min_index = [i for i, p in enumerate(pvals) if p == min_pval][0]\n",
    "        best_group = other_group[min_index]\n",
    "\n",
    "        if min_pval >= threshold:\n",
    "            # if min_pval >= threshold, user is not considered\n",
    "            # to have a good fit by any of distance metrics\n",
    "            best_group = None\n",
    "            min_pval = None\n",
    "\n",
    "    else:\n",
    "        best_group = None\n",
    "        min_pval = None\n",
    "\n",
    "    return (best_group, min_pval)\n",
    "\n",
    "def get_fit_score(fit_pvals, buffer_group, c, t=2):\n",
    "    \"\"\" calculate the fit score given the member composite\n",
    "        and its pvalues with its group distance metrics, with\n",
    "        c determinng the strength of penalty for keeping a \n",
    "        larger number of users in buffer_group\n",
    "        \n",
    "    Parameters:\n",
    "    -----------\n",
    "    fit_pvals: {dict}, {index: [pvalues]}\n",
    "    buffer_group: {list}, [userid, ...]\n",
    "    c: {float}, \n",
    "    t: {integer} 1, 2 or 3, type of fit score\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fit_score: {float}, fit score, a smaller value indidcate\n",
    "                a overall better fit\n",
    "    \n",
    "    Examples:\n",
    "    ---------\n",
    "    fit_group = fit_group\n",
    "    fit_pvals = fit_pvals\n",
    "    buffer_group = buffer_group\n",
    "    c = 0.1\n",
    "    fscore = get_fit_score(fit_group, fit_pvals, buffer_group, c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted sum of pvalues \n",
    "    if t not in [1, 2, 3]:\n",
    "        raise NameError('Error: type (t) is not legal value (1 or 2)!')\n",
    "    \n",
    "    wsum_pval = 0\n",
    "    if t == 1:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v) * 1.0 / len(v))\n",
    "    if t == 2:\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "    if t == 3:\n",
    "        num_users = 0\n",
    "        for g, v in fit_pvals.iteritems():\n",
    "            wsum_pval += sum(np.array(v)) * 1.0 / (len(v) * len(v))\n",
    "            num_users += len(v)\n",
    "        wsum_pval = num_users * 1.0 * wsum_pval\n",
    "\n",
    "    penalty = c * len(buffer_group)\n",
    "    fit_score = wsum_pval + penalty # smaller value indicates a better overall fit\n",
    "    \n",
    "    return fit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/sim_data_yi/\" \n",
    "\n",
    "users_df   = pd.read_csv(DATA_PATH + \"users_profile.csv\", header = 0, sep = \",\")\n",
    "friends_df = pd.read_csv(DATA_PATH + \"friendships.csv\", header = 0, sep = \",\")\n",
    "dist_df    = pd.read_csv(DATA_PATH + \"dist_mat.csv\", header = 0, sep = \",\")\n",
    "\n",
    "friends_df = friends_df[friends_df.isFriend == 1]\n",
    "friends_df[\"pair\"] = friends_df[[\"uid_a\", \"uid_b\"]].apply(lambda x: (int(x[0]), int(x[1])), axis=1)\n",
    "friends_df.drop(\"isFriend\", axis=1, inplace=True)\n",
    "friends_df = friends_df[[\"pair\", \"uid_a\", \"uid_b\"]]\n",
    "friends_df.head(3)\n",
    "\n",
    "cols = [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]\n",
    "\n",
    "## subset users data to retain profile only\n",
    "profile_df = users_df[[\"ID\"] + cols]\n",
    "all_user_ids = list(set(users_df.ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx import Graph\n",
    "from timeit import timeit\n",
    "\n",
    "fnx = Graph()\n",
    "fnx.add_edges_from(friends_df.pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input info.:\n",
    "----------\n",
    "profile_df\n",
    "friend_networkx\n",
    "\n",
    "control parameters:\n",
    "-------------------\n",
    "t: fit score type\n",
    "\n",
    "tuning parameter:\n",
    "-----------------\n",
    "threshold: cutoff value for kstest\n",
    "c: regularization strength\n",
    "min_delta_f: threshold for significant improvement\n",
    "max_iter: maxmium number of trivial trial learning in a row \n",
    "\"\"\"\n",
    "# input info\n",
    "k = 2 # user input\n",
    "\n",
    "# user_profile\n",
    "\n",
    "# final user interface\n",
    "# necessary\n",
    "# profile_df, \n",
    "# friends_ls\n",
    "# fnx\n",
    "\n",
    "profile_df = profile_df      # user profile\n",
    "friends_ls = friends_df.pair # user relationship \n",
    "friend_networkx = fnx        # user friendswork\n",
    "\n",
    "# tuing parameters\n",
    "t = 2               # type of Fit Score formula\n",
    "c = 0.1             # penalty for larger buffer group in Fit Score calculation\n",
    "threshold = 0.5     # ks-test threshold for fit or not fit\n",
    "n = 1000            # ks-test sample size for rayleigh \n",
    "min_size_group = 10 # minimal group size\n",
    "min_delta_f = 0.02  # minimal reduction for a significant fit improvement\n",
    "max_iter = 5       # max number of trivial iteration of learning\n",
    "\n",
    "# initiate the containers:\n",
    "dist_metrics = init_dict_list(k) # distance metrics containers\n",
    "fit_group = init_dict_list(k)    # members composition in fit groups\n",
    "fit_pvals = init_dict_list(k)    # members' pvalue of KStest with their group distance metrics\n",
    "unfit_group = init_dict_list(k)  # members is not considerd fit by its group distance metrics\n",
    "unfit_pvals = init_dict_list(k)  # pvalues for members in unfit_group (maybe can be deleted)\n",
    "buffer_group = []                # members are not considered having fit\n",
    "\n",
    "# results value\n",
    "fs_hist = []       # list of fit scores in sequence (lastest one is the last)\n",
    "knowledge_pkg = [] # {index: {\"dist_metrics\", \"fit_group\", \"buffer_group\"}} \n",
    "\n",
    "# calculate the the init distance metrics\n",
    "\n",
    "# sampling is subset of users to calculate\n",
    "# the distance metrics is good method\n",
    "\n",
    "# dist_metrics: ldm() with subset of users\n",
    "# fit_group: subsets of users\n",
    "# buffer_group: useres are not sampled \n",
    "\n",
    "# provide initial composition of fit_group\n",
    "# and buffer_group for iterative learning\n",
    "# procedure\n",
    "# the even sampling strategy is implemeted\n",
    "# here, however, \n",
    "all_uids = list(set(profile_df.ID))\n",
    "\n",
    "samp_size = len(all_uids) / k \n",
    "samp_sizes = [samp_size] * k\n",
    "all_uids_copy = [i for i in all_uids]\n",
    "# all_uids_copy = list(set(profile_df.ID))\n",
    "\n",
    "# generate k groups of sample user groups\n",
    "for g, samp_size in zip(range(k), samp_sizes):\n",
    "    # draw samples and assign them to fit_group\n",
    "    samples = choice(all_uids_copy, samp_size, replace=False)\n",
    "    fit_group[g] = list(samples)\n",
    "    # remove samples from population pool\n",
    "    for uid in samples:\n",
    "        all_uids_copy.remove(uid)\n",
    "\n",
    "# initiate fit user pvals\n",
    "for g, uids in fit_group.iteritems():\n",
    "    fit_pvals[g] = [0] * len(uids)\n",
    "        \n",
    "# if len(all_uids_copy) > 0:\n",
    "#     buffer_group = all_uids_copy\n",
    "# else:\n",
    "#    buffer_group = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "******************** iterative learning begins ************************************\n",
      "1 iteration is in processing ...\n",
      "--- 37.79 seconds ---\n",
      "--- 22.25 seconds ---\n",
      "ERROR: length(x) is different from length(y)!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4fb4342bab27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0muid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             sdist, ddist = user_grouped_dist(uid, target_dist, profile_df, \n\u001b[1;32m---> 35\u001b[1;33m                                          friend_networkx)\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mpval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_dist_kstest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_rayleigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_n\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-9f08245974c0>\u001b[0m in \u001b[0;36muser_grouped_dist\u001b[1;34m(user_id, weights, profile_df, friend_networkx)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnf_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnon_friends_ls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnonfriend_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprofile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnf_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mthe_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_euclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonfriend_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mdiff_dist_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36mweighted_euclidean\u001b[1;34m(x, y, w)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/spatial/distance.pyc\u001b[0m in \u001b[0;36meuclidean\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (7,) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/spatial/distance.py\u001b[0m(224)\u001b[0;36meuclidean\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    223 \u001b[1;33m    \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 224 \u001b[1;33m    \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    225 \u001b[1;33m    \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print uid\n",
      "*** NameError: name 'uid' is not defined\n",
      "ipdb> print uid\n",
      "*** NameError: name 'uid' is not defined\n",
      "ipdb> print uids\n",
      "*** NameError: name 'uids' is not defined\n",
      "ipdb> profile_df.head(5)\n",
      "*** NameError: name 'profile_df' is not defined\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# performance measurements\n",
    "durations = []\n",
    "\n",
    "_no_imp_counter = 0\n",
    "_loop_counter = 0\n",
    "\n",
    "print \"******************** iterative learning begins ************************************\"\n",
    "\n",
    "while _no_imp_counter < max_iter:\n",
    "    \n",
    "    _loop_counter += 1\n",
    "    print \"%d iteration is in processing ...\" % _loop_counter\n",
    "    start_time = timeit()\n",
    "    \n",
    "    # step 01: learn distance metrics\n",
    "    for g, uids in fit_group.iteritems():\n",
    "        # learn distance metrics\n",
    "        # here to update the computational mechanism\n",
    "        # dist = [np.random.uniform(0, 1, 1)[0] for i in range(4)]\n",
    "        if len(uids) >= min_size_group:\n",
    "            dist = ldm_train_with_list(uids, profile_df, friends_ls)\n",
    "            dist_metrics[g] = dist\n",
    "        else:\n",
    "            num_feat = profile_df.shape[1] - 1\n",
    "            dist_metrics[g] = [1] * num_feat\n",
    "        \n",
    "    # step 02: update the member composite with updated group \n",
    "    # distance metrics threshold is needed to be defined\n",
    "    fit_group_copy = {k:[i for i in v] for k, v in fit_group.iteritems()}\n",
    "    for g, uids in fit_group_copy.iteritems():\n",
    "        target_dist = dist_metrics[g]\n",
    "        for uid in uids:\n",
    "            sdist, ddist = user_grouped_dist(uid, target_dist, profile_df, \n",
    "                                         friend_networkx)\n",
    "            pval = user_dist_kstest(sdist, ddist, fit_rayleigh=True, _n=n)\n",
    "             \n",
    "            if pval >= threshold:\n",
    "                # remove the user and its information \n",
    "                # from relevant container\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_group[g].pop(idx)\n",
    "                # fit_group[g].remove(uid)\n",
    "                fit_pvals[g].pop(idx)\n",
    "                \n",
    "                # add the user to the unfit_group\n",
    "                if g in unfit_group:\n",
    "                    unfit_group[g].append(uid)\n",
    "                else:\n",
    "                    unfit_group[g] = [uid]\n",
    "            \n",
    "            else:\n",
    "                idx = [i for i, u in enumerate(fit_group[g]) if u == uid][0]\n",
    "                fit_pvals[g][idx] = pval\n",
    "                \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"1) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    # step 03: test members in unfit_group to see\n",
    "    # if it has a good fit with other distmetrics\n",
    "    # make a copy of the buffer group container\n",
    "    buffer_group_copy = [i for i in buffer_group]\n",
    "    if len(buffer_group_copy) > 0:\n",
    "        for uid in buffer_group_copy:\n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, \n",
    "                                                 profile_df, friend_networkx, threshold)\n",
    "            if new_group is not None:\n",
    "                buffer_group.remove(uid)\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"2) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                    \n",
    "    unfit_group_copy = {k:[i for i in v] for k, v in unfit_group.iteritems()}\n",
    "    for g, uids in unfit_group_copy.iteritems():\n",
    "        for uid in uids:        \n",
    "            new_group, new_pval = find_fit_group(uid, dist_metrics, profile_df, \n",
    "                                                 friend_networkx, threshold, g)\n",
    "            unfit_group[g].remove(uid)\n",
    "\n",
    "            if new_pval is None:\n",
    "                buffer_group.append(uid)\n",
    "            else:\n",
    "                if new_group in fit_group:\n",
    "                    fit_group[new_group].append(uid)\n",
    "                    fit_pvals[new_group].append(new_pval)\n",
    "                else:\n",
    "                    fit_group[new_group] = [uid]\n",
    "                    fit_pvals[new_group] = [new_pval]\n",
    "                    \n",
    "    tot_fit_group = np.sum([len(u) for g, u in fit_group.iteritems()])\n",
    "    tot_unfit_group = np.sum([len(u) for g, u in unfit_group.iteritems()])\n",
    "    tot_buffer_group = len(buffer_group)\n",
    "    print \"3) #fit: %d, #unfit: %d, #buffer: %d\" % (tot_fit_group, tot_unfit_group, tot_buffer_group)\n",
    "                        \n",
    "    # step 04: calculate fit score\n",
    "    fs = get_fit_score(fit_pvals, buffer_group, c=c, t=1)\n",
    "    fs_hist.append(fs)\n",
    "    \n",
    "    # step 05: evaluate stop criteria\n",
    "    package = {\"dist_metrics\": dist_metrics, \n",
    "               \"fit_group\": fit_group, \n",
    "               \"buffer_group\": buffer_group}\n",
    "\n",
    "    knowledge_pkg.append(package)\n",
    "    best_fs = min(fs_hist)\n",
    "\n",
    "    if best_fs - fs <= min_delta_f:\n",
    "        _no_imp_counter += _no_imp_counter \n",
    "    else:\n",
    "        _no_imp_counter = 0\n",
    "        if threshold > 0.2:\n",
    "            threshold -= 0.01\n",
    "        \n",
    "    # print \"fit score (type-%d): %.3f\" % (t, fs)\n",
    "    # print \"best fit score: %.3f\" % best_fs\n",
    "    end_time = timeit()\n",
    "    duration = end_time - start_time\n",
    "    durations.append(duration)\n",
    "    print \"time elapsed: %.4f s\" % duration\n",
    "     \n",
    "print \"******************** ends ************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "ERROR: length(x) is different from length(y)!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (6,) (7,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-49d663b3b7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'pdb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m sdist, ddist = user_grouped_dist(uid, target_dist, profile_df, \n\u001b[1;32m----> 3\u001b[1;33m                                          friend_networkx)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-9f08245974c0>\u001b[0m in \u001b[0;36muser_grouped_dist\u001b[1;34m(user_id, weights, profile_df, friend_networkx)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnf_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnon_friends_ls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mnonfriend_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprofile_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnf_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mthe_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_euclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnonfriend_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mdiff_dist_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/dist_metrics.pyc\u001b[0m in \u001b[0;36mweighted_euclidean\u001b[1;34m(x, y, w)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/anaconda/lib/python2.7/site-packages/scipy/spatial/distance.pyc\u001b[0m in \u001b[0;36meuclidean\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (7,) "
     ]
    }
   ],
   "source": [
    "sdist, ddist = user_grouped_dist(uid, target_dist, profile_df, \n",
    "                                         friend_networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "[0.53, 0.44, 0.0, 0.02, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print uid\n",
    "print target_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
