{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import networkx as nx\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from learning_dist_metrics import ldm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(\"data/drhuang_person.csv\", header=0)\n",
    "friend_df = pd.read_csv(\"data/drhuang_friend.csv\", header=0,)\n",
    "\n",
    "## split data by column\n",
    "uid_df = user_df[\"ID\"]\n",
    "profile_df = user_df[[c for c in user_df.columns if c != \"ID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "friend_df.head(3)\n",
    "#friend_df.columns = [\"\"range(0, friend_df.shape[1]-1)\n",
    "relation_mtx = friend_df.ix[:, 1:]\n",
    "relation_mtx.head(4)\n",
    "\n",
    "friend_pairs = []\n",
    "uid_row = friend_df.ix[:, 0]\n",
    "uid_col = uid_row\n",
    "\n",
    "# convert relationship matrix into a list of user pairs\n",
    "# to represent friendships, iterating through items\n",
    "# on the lower triangle of the matrix\n",
    "for i, uid_a in enumerate(uid_row):\n",
    "    for j, uid_b in enumerate(uid_col):\n",
    "\n",
    "        if uid_a < uid_b:\n",
    "            ind = relation_mtx.ix[i, j]\n",
    "            if ind == 1:\n",
    "                friend_pairs.append((uid_a, uid_b))\n",
    "\n",
    "# load relationship into networkx.Graph()\n",
    "from networkx import Graph\n",
    "\n",
    "fnx = Graph()\n",
    "fnx.add_edges_from(friend_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scalar(x):\n",
    "    _min, _max = min(x), max(x)\n",
    "    _range = (_max - _min) * 1.0\n",
    "    res = [(i - _min) / _range for i in x]\n",
    "    return res\n",
    "\n",
    "## transform data\n",
    "new_profile_df = pd.DataFrame()\n",
    "new_profile_df[\"Gender\"]    = profile_df.ix[:, 0]\n",
    "new_profile_df[\"Age\"]       = scalar(profile_df[\"Age\"])\n",
    "new_profile_df[\"Region\"]    = scalar(profile_df[\"Region\"])\n",
    "new_profile_df[\"Education\"] = scalar(profile_df[\"Education\"])\n",
    "new_profile_df[\"Income\"]    = scalar(profile_df[\"Income\"])\n",
    "new_profile_df[\"Hobby\"]     = scalar(profile_df[\"Hobby\"])\n",
    "new_profile_df[\"Duration\"]  = scalar(profile_df[\"Duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import ks_2samp\n",
    "from numpy import linspace\n",
    "from numpy.random import choice\n",
    "from networkx import Graph\n",
    "from learning_dist_metrics.ldm import LDM\n",
    "from learning_dist_metrics.dist_metrics import weighted_euclidean\n",
    "\n",
    "\n",
    "def user_grouped_dist(user_id, weights, profile_df, friends_networkx):\n",
    "    \"\"\" Calculate distances between a user and whose friends\n",
    "        and distance between a user and whose non-friends.\n",
    "        The groupped distance vector will be output.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    * user_id: {integer}, the target user's ID\n",
    "    * weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    * profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    * friends_networkx: {networkx.Graph()}, Graph() object from Networkx\n",
    "        to store the relationships informat\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list, list of integers}, a list of two lists, which store the distances\n",
    "        of either friends and non-friends separately.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[ [\"ID\"] + cols ]\n",
    "    user_dist = user_grouped_dist(user_id = 0, weights = weights\n",
    "        , profile_df, friends_df)\n",
    "    print user_dist[\"friends\"]\n",
    "    print user_dist[\"nonfriends\"]\n",
    "    \"\"\"\n",
    "    cols = [col for col in profile_df.columns if col is not \"ID\"]\n",
    "    # get the user profile information of the target users\n",
    "    user_profile = profile_df.ix[profile_df.ID == user_id, cols].as_matrix()\n",
    "    # get the user_id of friends of the target user\n",
    "    friends_ls = friends_networkx.neighbors(user_id)\n",
    "    all_ids = profile_df.ID\n",
    "    non_friends_ls = [u for u in all_ids if u not in friends_ls + [user_id]]\n",
    "\n",
    "    sim_dist_vec = []\n",
    "    for f_id in friends_ls:\n",
    "        friend_profile = profile_df.ix[profile_df.ID == f_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, friend_profile, weights)\n",
    "        sim_dist_vec.append(the_dist)\n",
    "\n",
    "    diff_dist_vec = []\n",
    "    for nf_id in non_friends_ls:\n",
    "        nonfriend_profile = profile_df.ix[profile_df.ID == nf_id, cols].as_matrix()\n",
    "        the_dist = weighted_euclidean(user_profile, nonfriend_profile, weights)\n",
    "        diff_dist_vec.append(the_dist)\n",
    "\n",
    "    res = [sim_dist_vec, diff_dist_vec]\n",
    "    return res\n",
    "\n",
    "\n",
    "def user_dist_kstest(sim_dist_vec, diff_dist_vec,\n",
    "                     fit_rayleigh=False, _n=100):\n",
    "\t\t\t\t\t\t \n",
    "    \"\"\" Test the goodness of a given weights to defferentiate friend distance\n",
    "        distributions and non-friend distance distributions of a given user.\n",
    "        The distance distribution is considered to follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    sim_dist_vec: {vector-like (list), float}, distances between friends\n",
    "                  and the user\n",
    "    diff_dist_vec: {vector-like (list), float}, distances between non-fri\n",
    "                   -ends and the user\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    * res: {float}: p-value of ks-test with assumption that distances follow\n",
    "            Rayleigh distribution.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    pval = user_dist_kstest(sim_dist_vec, diff_dist_vec)\n",
    "    \"\"\"\n",
    "    # is_valid = (len(sim_dist_vec) >= min_nobs) & \\\n",
    "    #           (len(diff_dist_vec) >= min_nobs) # not used yet\n",
    "    if fit_rayleigh:\n",
    "        friend_param = rayleigh.fit(sim_dist_vec)\n",
    "        nonfriend_param = rayleigh.fit(diff_dist_vec)\n",
    "\n",
    "        samp_friend = rayleigh.rvs(friend_param[0], friend_param[1], _n)\n",
    "        samp_nonfriend = rayleigh.rvs(nonfriend_param[0], nonfriend_param[1], _n)\n",
    "\n",
    "        # ouput p-value of ks-test\n",
    "        res = ks_2samp(samp_friend, samp_nonfriend)[1]\n",
    "    else:\n",
    "        res = ks_2samp(sim_dist_vec, diff_dist_vec)[1]\n",
    "\t\t\n",
    "    return res\n",
    "\n",
    "\n",
    "def users_filter_by_weights(weights, profile_df, friends_networkx,\n",
    "                            pval_threshold=0.5, \n",
    "                            mutate_rate=0.4,\n",
    "                            min_friend_cnt=10, \n",
    "                            users_list=None,\n",
    "                            fit_rayleigh=False, \n",
    "                            _n=1000,\n",
    "                            is_debug=False):\n",
    "    \"\"\" Split users into two groups, \"keep\" and \"mutate\", with respect to\n",
    "        p-value of the ks-test on the null hypothesis that the distribution of\n",
    "        friends' weighted distance is not significantly different from the\n",
    "        couterpart for non-friends. Assume the weighted distances of each group\n",
    "        follow Rayleigh distribution.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    weights: {vector-like, float}, the vector of feature weights which\n",
    "        is extracted by LDM().fit(x, y).get_transform_matrix()\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends_networkx: {networkx.Graph()}, Graph() object from Networkx to store\n",
    "        the relationships information\n",
    "    pval_threshold: {float}, the threshold for p-value to reject hypothesis\n",
    "    min_friend_cnt: {integer}, drop users whose total of friends is less than\n",
    "       this minimum count\n",
    "    mutate_rate: {float}, a float value [0 - 1] determine the percentage of\n",
    "       bad_fits member sent to mutation\n",
    "    fit_rayleigh: {boolean}, determine if fit data into Rayleigth distri\n",
    "                  -bution\n",
    "    _n: {integer}, number of random samples generated from estimated\n",
    "        distribution\n",
    "    is_debug: {boolean}, to control if it yeilds by-product information\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {list} grouped list of user ids\n",
    "        res[0] stores all users whose null hypothesis does not holds;\n",
    "        res[1] stores all users whose null hypothesis hold null hypothesis,\n",
    "        given weights, distance distribution of all friends is significantly\n",
    "        different from distance distribution of all non-friends\n",
    "\n",
    "    Examples:\n",
    "    --------\n",
    "    weights = ldm().fit(df, friends_list).get_transform_matrix()\n",
    "    profile_df = users_df[[\"ID\"] + cols]\n",
    "    grouped_users = users_filter_by_weights(weights,\n",
    "                       profile_df, friends_df, pval_threshold = 0.10,\n",
    "                       min_friend_cnt = 10)\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    min_friend_cnt is not implemented\n",
    "    \"\"\"\n",
    "    # all_users_ids = list(set(profile_df.ID))\n",
    "    # users_list\n",
    "    # container for users meeting different critiria\n",
    "    pvals = []\n",
    "    if users_list is None:\n",
    "        users_list = list(profile_df.ix[:, 0])\n",
    "\n",
    "    for uid in users_list:\n",
    "        res_dists = user_grouped_dist(uid, weights, profile_df, friends_networkx)\n",
    "        pval = user_dist_kstest(res_dists[0], res_dists[1], fit_rayleigh, _n)\n",
    "        pvals.append(pval)\n",
    "\n",
    "    sorted_id_pval = sorted(zip(users_list, pvals), key=lambda x: x[1])\n",
    "    good_fits = [i for i, p in sorted_id_pval if p < pval_threshold]\n",
    "    bad_fits = [i for i, p in sorted_id_pval if p >= pval_threshold]\n",
    "    \n",
    "    if len(bad_fits) > 0:\n",
    "        mutate_size = np.ceil(len(bad_fits) * mutate_rate)\n",
    "        mutate_size = max(int(mutate_size), 1)\n",
    "        id_retain = good_fits + bad_fits[mutate_size:]\n",
    "        id_mutate = bad_fits[:mutate_size]\n",
    "    else:\n",
    "        id_retain = good_fits\n",
    "        id_mutate = bad_fits\n",
    "        \n",
    "    if is_debug is True:\n",
    "        res = [id_retain, id_mutate, sorted_id_pval]\n",
    "    else:\n",
    "        res = [id_retain, id_mutate]\n",
    "    return res\n",
    "\n",
    "\n",
    "def ldm_train_with_list(users_list, profile_df, friends, retain_type=1):\n",
    "    \"\"\" learning distance matrics with ldm() instance, provided with selected\n",
    "        list of users.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    users_list: {vector-like, integer}, the list of user id\n",
    "    profile_df: {matrix-like, pandas.DataFrame}, user profile dataframe\n",
    "        with columns: [\"ID\", \"x0\" - \"xn\"]\n",
    "    friends: {list of tuple}, each tuple keeps a pair of user id\n",
    "    retain_type: {integer}, 0, adopting 'or' logic by keeping relationship in\n",
    "        friends_df if either of entities is in user_list 1, adopting 'and'\n",
    "        logic\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    res: {vector-like, float}, output of ldm.get_transform_matrix()\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    new_dist_metrics = ldm_train_with_list(user_list, profile_df, friends_df)\n",
    "    \"\"\"\n",
    "    if retain_type == 0:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list or b in users_list]\n",
    "    else:\n",
    "        friends = [(a, b) for a, b in friends if \\\n",
    "            a in users_list and b in users_list]\n",
    "    \n",
    "    ldm = LDM()    \n",
    "    ldm.fit(profile_df, friends)\n",
    "    weight_vec = ldm.get_transform_matrix()\n",
    "    return weight_vec     \n",
    "\n",
    "\n",
    "def hyper_parameter_tester(weights_a, weights_b, fit_rayleigh, num):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    num_friends = []\n",
    "    num_nonfriends = []\n",
    "    ks_pvals_right = []\n",
    "    ks_pvals_wrong = []\n",
    "\n",
    "    for uid in tg0_ids: \n",
    "        # Compare the distribution of a user's distances of all of his/her friends\n",
    "        # against the distribuiton of a users's distances of all of his/her non-friends,\n",
    "        # The collection of non-friends may include those users of two categories with\n",
    "        # respect to their relationships to the target user: \n",
    "        # a. the users who are not likened by the target users \n",
    "        # b. the users who are likely to be befriended by the users however\n",
    "        #    the users do not have a change to be exposed to her/him.\n",
    "        sim_dists, diff_dists = user_grouped_dist(uid, weights_a, profile_df, fnx)\n",
    "        pval = user_dist_kstest(sim_dists, diff_dists, fit_rayleigh=fit_rayleigh, _n = num)\n",
    "        ks_pvals_right.append(pval)\n",
    "    \n",
    "        sim_dists, diff_dists = user_grouped_dist(uid, weights_b, profile_df, fnx)\n",
    "        pval = user_dist_kstest(sim_dists, diff_dists, fit_rayleigh=fit_rayleigh, _n = num)\n",
    "        ks_pvals_wrong.append(pval)\n",
    "    \n",
    "        num_friends.append(len(sim_dists))\n",
    "        num_nonfriends.append(len(diff_dists))\n",
    "    \n",
    "    res_report = pd.DataFrame({\"ID\": tg0_ids, \n",
    "\t\t                       \"num_friends\": num_friends, \n",
    "                               \"num_nonfriends\": num_nonfriends, \n",
    "                               \"true_pval\": ks_pvals_right,\n",
    "                               \"wrong_pval\": ks_pvals_wrong})\n",
    "\t\t\t\t\t\t\t   \n",
    "    return res_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2b7c491dc897>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mall_uids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldm_train_with_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_uids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_profile_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfriend_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-c58932d6ff09>\u001b[0m in \u001b[0;36mldm_train_with_list\u001b[1;34m(users_list, profile_df, friends, retain_type)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0mldm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfriends\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[0mweight_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweight_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, S, D)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0m_ratio\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"\"\"\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, S, D)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;31m# a set of two distance functions, squared_sum_grouped_dist() and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# sum_grouped_dist()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0mS_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mD_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/beingzy/Documents/projects/phd_experiment/learning_dist_metrics/ldm.pyc\u001b[0m in \u001b[0;36mfind_index\u001b[1;34m(val, array)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \"\"\"\n\u001b[0;32m    263\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "all_uids = user_df[\"ID\"].unique()\n",
    "\n",
    "w = ldm_train_with_list(all_uids, new_profile_df, friend_pairs, retain_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid_freq = {}\n",
    "for a, b in friend_pairs:\n",
    "\n",
    "    if a in uid_freq:\n",
    "        uid_freq[a] += 1\n",
    "    else:\n",
    "        uid_freq[a] = 1\n",
    "    \n",
    "    if b in uid_freq:\n",
    "        uid_freq[b] += 1\n",
    "    else:\n",
    "        uid_freq[b] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uid_freq.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
